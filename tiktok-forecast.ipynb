{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp as yt\n",
    "import whisper\n",
    "import pyktok as pyk\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import spacy\n",
    "import os\n",
    "import ffmpeg\n",
    "import easyocr\n",
    "import shutil\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from ShazamAPI import Shazam\n",
    "from langdetect import detect, DetectorFactory\n",
    "import re\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"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\"\n",
    "gpt_client = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client\n",
    "\n",
    "url: str = \"https://pqhcubzkrlbvljbvsmem.supabase.co\"\n",
    "key: str = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InBxaGN1YnprcmxidmxqYnZzbWVtIiwicm9sZSI6ImFub24iLCJpYXQiOjE3Mjc4NzgyNDYsImV4cCI6MjA0MzQ1NDI0Nn0.5Yt2zMMm09II29COY58lXIvIQID1N7FM6JL3-B9jhdU\"\n",
    "supabase: Client = create_client(url, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client(\"s3\")\n",
    "\n",
    "DB_CONNECTION = \"postgresql://postgres.pqhcubzkrlbvljbvsmem:baw1mART4@aws-0-eu-west-3.pooler.supabase.com:5432/postgres\"\n",
    "DB_PASSWORD = \"baw1mART4-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_FOLDER = \"FRAMES\"\n",
    "RAW_DATA_FOLDER = \"DATA\"\n",
    "\n",
    "os.mkdir(FRAME_FOLDER)\n",
    "os.mkdir(RAW_DATA_FOLDER)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://www.tiktok.com/@ruskazmrzlinaa/video/7335805600019877128?q=berlin&t=1727902781177\"  \n",
    "output_filename = f\"{RAW_DATA_FOLDER}/audio\"\n",
    "audio_filename = f\"{RAW_DATA_FOLDER}/audio.mp3\"\n",
    "output_metadata_filename=f\"{RAW_DATA_FOLDER}/video_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tiktok_audio(video_url, output_filename):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': output_filename,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "    }\n",
    "\n",
    "    with yt.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([video_url])\n",
    "\n",
    "def transcript_audio_to_text(audio_filename, is_music):\n",
    "    if is_music is False : \n",
    "        model = whisper.load_model(\"base\")\n",
    "        result = model.transcribe(audio_filename)\n",
    "        text = result[\"text\"]\n",
    "        print(f\"text : {result[\"text\"]}\")\n",
    "\n",
    "\n",
    "        return text\n",
    "    else:\n",
    "        return \"\", \" \"\n",
    "\n",
    "\n",
    "def get_tiktok_metadata(video_url, output_metadata_filename):\n",
    "    pyk.save_tiktok(video_url,\n",
    "                False,\n",
    "                output_metadata_filename)\n",
    "    \n",
    "\n",
    "def extract_metadata(output_metadata_filename):\n",
    "    data = pd.read_csv(output_metadata_filename)\n",
    "    video_author = data[\"author_username\"][0]\n",
    "    video_id = data[\"video_id\"][0]\n",
    "    video_time = data[\"video_duration\"][0]\n",
    "    video_title = f\"@{video_author}_video_{video_id}.mp4\"\n",
    "    video_description = data[\"video_description\"][0]\n",
    "    return video_title, video_description, video_time\n",
    "\n",
    "\n",
    "def download_video(video_url, output_metadata_filename, video_time):\n",
    "    if video_time <= 150:\n",
    "        pyk.save_tiktok(video_url,\n",
    "                True,\n",
    "                output_metadata_filename)\n",
    "\n",
    "\n",
    "def extract_video_frames(video_title , video_time, fps = 1):\n",
    "    if video_time > 150:\n",
    "        print(\"Video too long, no video extraction\")\n",
    "        return \n",
    "    else:\n",
    "        output_frames = f'{FRAME_FOLDER}/frame_%04d.png'\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(video_title)\n",
    "            .output(output_frames, vf=f'fps={fps}')\n",
    "            .run()\n",
    "        )\n",
    "\n",
    "        print(\"Frames extraction done.\")\n",
    "\n",
    "\n",
    "def create_reader():\n",
    "    reader = easyocr.Reader(['en','fr','es','it','de'])\n",
    "    return reader\n",
    "\n",
    "\n",
    "def extract_text_from_frames(reader, frame_folder, video_time):\n",
    "    if video_time > 150 : \n",
    "        print(\"no frame extraction\")\n",
    "        return \" \"\n",
    "    else:\n",
    "        video_frame_text = []\n",
    "        for frame in os.listdir(frame_folder):\n",
    "            result = reader.readtext(f\"{frame_folder}/{frame}\")\n",
    "            for detection in result:\n",
    "                video_frame_text.append(detection[1])\n",
    "        print( video_frame_text)\n",
    "        return video_frame_text\n",
    "\n",
    "\n",
    "def generate_input_text(video_description, video_audio, video_frame_text):\n",
    "    generated_texts = video_description , video_audio ,  \" \".join(video_frame_text)\n",
    "    print( generated_texts)\n",
    "    return generated_texts\n",
    "\n",
    "\n",
    "def forecast_places(input_generated_texts):\n",
    "    nlp = spacy.load(\"xx_ent_wiki_sm\")\n",
    "    doc = nlp(str(input_generated_texts))\n",
    "    forecasted_places = [ent.text for ent in doc.ents if ent.label_  in [\"LOC\"]]\n",
    "    print(\"forecasted places :\", forecasted_places)\n",
    "    return forecasted_places\n",
    "\n",
    "\n",
    "def check_audio(audio_file_name): \n",
    "    try:\n",
    "        with open(audio_file_name, 'rb') as audio_file:\n",
    "            mp3_file_content_to_recognize = audio_file.read()\n",
    "        \n",
    "            shazam = Shazam(mp3_file_content_to_recognize)\n",
    "            recognize_generator = shazam.recognizeSong()\n",
    "            if True:\n",
    "                print(\"Identified music.\")\n",
    "                return False\n",
    "    except FileNotFoundError:\n",
    "        print(\"No music\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error append: {e}\")\n",
    "    return False\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    text = re.sub(r'[@#]\\w+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s,.\\'â€™-]', '', text) \n",
    "    return text\n",
    "\n",
    "\n",
    "def nlp_forecast(client, text): \n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"You are usefull to seek places in a text with their city and country\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "            \"\"\"\n",
    "            Instructions:\n",
    "                - Given the text at the end, find all the places to visit quote in this text. \n",
    "                - Return the number of places you find\n",
    "                - Return the city of these places in English\n",
    "                - Return the country of these places in English\n",
    "                - Do not return the same place multiple time\n",
    "                - Return only in the python dictionary format like below\n",
    "                - Do not include any additional formatting, such as markdown code blocks\n",
    "\n",
    "\n",
    "            {\n",
    "            \"place_number\" : \"<number of places>\",\n",
    "            \"place_1\" : \"<first place you find in the text>\",\n",
    "            \"place_2\" : \"<second place you find in the text>\", \n",
    "            ...,\n",
    "            \"place_n\" : \"<the nth place you find in the text>\n",
    "            \"city\" :\" <the city of these places>\", \n",
    "            \"country\" : \"<the country of these places>\"\n",
    "             },\n",
    "\n",
    "             \n",
    "            The text could be bad formated but just focus to find similitude with the places you know \n",
    "            There is the text to analyse :\n",
    "            \"\"\" + text\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "    output = completion.choices[0].message.content\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    words = text.split()\n",
    "    seen = set()\n",
    "    unique_words = []\n",
    "    for word in words:\n",
    "        if word not in seen:\n",
    "            unique_words.append(word)\n",
    "            seen.add(word)\n",
    "    \n",
    "    return ' '.join(unique_words)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = re.sub(r\"[^\\w\\s,]\", \"\", text)\n",
    "    cleaned_text = re.sub(r\",+\", \",\", cleaned_text)\n",
    "    cleaned_text = cleaned_text.replace(\",,\", \",\")  \n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TikTok] Extracting URL: https://www.tiktok.com/@ruskazmrzlinaa/video/7335805600019877128?q=berlin&t=1727902781177\n",
      "[TikTok] 7335805600019877128: Downloading webpage\n",
      "[info] 7335805600019877128: Downloading 1 format(s): bytevc1_1080p_1578352-1\n",
      "[download] Destination: DATA/audio\n",
      "[download] 100% of    2.21MiB in 00:00:00 at 2.43MiB/s   \n",
      "[ExtractAudio] Destination: DATA/audio.mp3\n",
      "Deleting original file DATA/audio (pass -k to keep)\n",
      "Identified music.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/miniconda3/envs/testing/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/Users/user/miniconda3/envs/testing/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text :  IN\n",
      "Saved metadata for video\n",
      " https://www.tiktok.com/@ruskazmrzlinaa/video/7335805600019877128?q=berlin&t=1727902781177 \n",
      "to\n",
      " /Users/user/Documents/ProjetIATiktok\n",
      "video time : 11 seconds\n",
      "Saved video\n",
      " https://www.tiktok.com/@ruskazmrzlinaa/video/7335805600019877128?q=berlin&t=1727902781177 \n",
      "to\n",
      " /Users/user/Documents/ProjetIATiktok\n",
      "Saved metadata for video\n",
      " https://www.tiktok.com/@ruskazmrzlinaa/video/7335805600019877128?q=berlin&t=1727902781177 \n",
      "to\n",
      " /Users/user/Documents/ProjetIATiktok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.0.2_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '@ruskazmrzlinaa_video_7335805600019877128.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    comment         : vid:v14044g50000cn7062vog65q3bmkcuq0\n",
      "    aigc_info       : {\"aigc_label_type\": 0}\n",
      "    encoder         : Lavf58.76.100\n",
      "  Duration: 00:00:11.77, start: 0.000000, bitrate: 2556 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 576x1024 [SAR 1:1 DAR 9:16], 2516 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](und): Audio: aac (HE-AACv2) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 32 kb/s (default)\n",
      "      Metadata:\n",
      "        handler_name    : SoundHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x138fe0000] [swscaler @ 0x138ff0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138fe0000] [swscaler @ 0x1502c8000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138fe0000] [swscaler @ 0x150350000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138fe0000] [swscaler @ 0x150360000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138fe0000] [swscaler @ 0x150370000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138fe0000] [swscaler @ 0x150380000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138fe0000] [swscaler @ 0x150390000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138fe0000] [swscaler @ 0x1503a0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138fe0000] [swscaler @ 0x1503b0000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "Output #0, image2, to 'FRAMES/frame_%04d.png':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    comment         : vid:v14044g50000cn7062vog65q3bmkcuq0\n",
      "    aigc_info       : {\"aigc_label_type\": 0}\n",
      "    encoder         : Lavf61.1.100\n",
      "  Stream #0:0(und): Video: png, rgb24(pc, gbr/bt709/bt709, progressive), 576x1024 [SAR 1:1 DAR 9:16], q=2-31, 200 kb/s, 1 fps, 1 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.3.100 png\n",
      "[out#0/image2 @ 0x14ce0ecc0] video:11609KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: unknown\n",
      "frame=   12 fps=0.0 q=-0.0 Lsize=N/A time=00:00:12.00 bitrate=N/A speed=46.3x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames extraction done.\n",
      "['Free place to visit in', 'Berlin', 'Oâ‚¬', 'Highly recommended', '0', '1', '8', 'SER DE', '{', '', 'MkK', 'Free place to visit in', 'Berlin', '0â‚¬', 'Highly recommended', 'AAn', 'Taae [', '6', 'SEE GAER +', 'Freeplace tovisit in', 'Berlin', 'Oâ‚¬', 'Highly recommended', 'Urban Mation', 'Fteeplaceto visit in', 'Berlin', '@â‚¬', 'Free place to visit in', 'Berlin', 'Oâ‚¬', 'Free place to visit in', 'Berlin', 'oâ‚¬', 'Highly recommended', 'Urban Nation', 'Urban Nation', 'Free place to visit in', 'Berlin', 'Oâ‚¬', 'Highly recommended', 'Urban Nation', 'JTHORITAKIFY', '(eckol)', '14/88', 'etmor', \"'Ã®t\", 'Ia', 'kb', 'THE S7ATE', 'SCL Groy', 'To', '1D[eo', 'ALPAA MAe', '1', 'NORMIE', 'amazon', 'CUCKHGUE', 'Dbo', '@@d', 'MSM', 'Uber', 'N', '~libral', 'altl-%qht', 'M', 'TEMoNgY', 'C3', 'ROTE', 'Freeplace to visit in', 'Berlin', 'YouTihe', 'NOWAS', '0â‚¬', 'dom', 'RTARIAN\"', 'PREPP']\n",
      "('#deutschland #berlin #berlingo #berlinlebt #museum #world2024 #immigration #travel #germanytravel #germanytiktok #germanyðŸ‡©ðŸ‡ª #german ', ' IN', 'Free place to visit in Berlin Oâ‚¬ Highly recommended 0 1 8 SER DE {  MkK Free place to visit in Berlin 0â‚¬ Highly recommended AAn Taae [ 6 SEE GAER + Freeplace tovisit in Berlin Oâ‚¬ Highly recommended Urban Mation Fteeplaceto visit in Berlin @â‚¬ Free place to visit in Berlin Oâ‚¬ Free place to visit in Berlin oâ‚¬ Highly recommended Urban Nation Urban Nation Free place to visit in Berlin Oâ‚¬ Highly recommended Urban Nation JTHORITAKIFY (eckol) 14/88 etmor \\'Ã®t Ia kb THE S7ATE SCL Groy To 1D[eo ALPAA MAe 1 NORMIE amazon CUCKHGUE Dbo @@d MSM Uber N ~libral altl-%qht M TEMoNgY C3 ROTE Freeplace to visit in Berlin YouTihe NOWAS 0â‚¬ dom RTARIAN\" PREPP')\n",
      "cleaned text : '            ', ' IN', 'Free place to visit in Berlin O Highly recommended 0 1 8 SER DE   MkK Free place to visit in Berlin 0 Highly recommended AAn Taae  6 SEE GAER  Freeplace tovisit in Berlin O Highly recommended Urban Mation Fteeplaceto visit in Berlin  Free place to visit in Berlin O Free place to visit in Berlin o Highly recommended Urban Nation Urban Nation Free place to visit in Berlin O Highly recommended Urban Nation JTHORITAKIFY eckol 1488 etmor 't Ia kb THE S7ATE SCL Groy To 1Deo ALPAA MAe 1 NORMIE amazon CUCKHGUE Dbo  MSM Uber N libral altl-qht M TEMoNgY C3 ROTE Freeplace to visit in Berlin YouTihe NOWAS 0 dom RTARIAN PREPP'\n"
     ]
    }
   ],
   "source": [
    "download_tiktok_audio(video_url, output_filename)\n",
    "is_music = check_audio(audio_filename)\n",
    "video_audio = transcript_audio_to_text(audio_filename, is_music)\n",
    "get_tiktok_metadata(video_url, output_metadata_filename)\n",
    "video_title, video_description, video_time = extract_metadata(output_metadata_filename)\n",
    "print(f\"video time : {video_time} seconds\")\n",
    "download_video(video_url, output_metadata_filename, video_time)\n",
    "extract_video_frames(video_title, video_time)\n",
    "reader = create_reader()\n",
    "video_frame_text = extract_text_from_frames(reader, frame_folder=FRAME_FOLDER, video_time=video_time)\n",
    "input_text = generate_input_text(video_description, video_audio, video_frame_text)\n",
    "cleaned_text = clean_text(str(input_text))\n",
    "print(\"cleaned text : \" + cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", IN, Free place to visit in Berlin O Highly recommended 0 1 8 SER DE MkK Free AAn Taae 6 SEE GAER Freeplace tovisit Urban Mation Fteeplaceto o Nation JTHORITAKIFY eckol 1488 etmor t Ia kb THE S7ATE SCL Groy To 1Deo ALPAA MAe NORMIE amazon CUCKHGUE Dbo MSM Uber N libral altlqht M TEMoNgY C3 ROTE YouTihe NOWAS dom RTARIAN PREPP\n"
     ]
    }
   ],
   "source": [
    "new = remove_duplicates(cleaned_text)\n",
    "new = preprocess_text(new)\n",
    "\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", IN, Free place to visit in Berlin O Highly recommended 0 1 8 SER DE MkK Free AAn Taae 6 SEE GAER Freeplace tovisit Urban Mation Fteeplaceto o Nation JTHORITAKIFY eckol 1488 etmor t Ia kb THE S7ATE SCL Groy To 1Deo ALPAA MAe NORMIE amazon CUCKHGUE Dbo MSM Uber N libral altlqht M TEMoNgY C3 ROTE YouTihe NOWAS dom RTARIAN PREPP\n",
      "{\n",
      "\"place_number\" : \"1\",\n",
      "\"place_1\" : \"Urban Nation\",\n",
      "\"city\" : \"Berlin\", \n",
      "\"country\" : \"Germany\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_number</th>\n",
       "      <th>place_1</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Urban Nation</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  place_number       place_1    city  country\n",
       "0            1  Urban Nation  Berlin  Germany"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(new)\n",
    "output = nlp_forecast(gpt_client, str(input_text))\n",
    "dico = eval(output)\n",
    "data = pd.DataFrame(dico, index=[0])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = int(data[\"place_number\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Urban Nation'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"place_1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_places = []\n",
    "for i in range(1, pn+1):\n",
    "    list_of_places.append(data[f\"place_{i}\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = (\n",
    "    supabase.table(\"generated_text\")\n",
    "    .insert({\n",
    "        \"video_url\": video_url,\n",
    "        \"video_description_text\" : video_description,\n",
    "        \"video_frame_text\" : video_frame_text ,\n",
    "        \"video_audio_text\" : video_audio,\n",
    "        \"video_cleaned_text\" : cleaned_text,\n",
    "        \"place_number\" : int(data[\"place_number\"][0]),\n",
    "        \"place_city\" : data[\"city\"][0],\n",
    "        \"place_country\" : data[\"country\"][0],\n",
    "        \"output\" : list_of_places\n",
    "        })\n",
    "    .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(FRAME_FOLDER)\n",
    "shutil.rmtree(RAW_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
