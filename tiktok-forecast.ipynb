{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp as yt\n",
    "import whisper\n",
    "import pyktok as pyk\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import spacy\n",
    "import os\n",
    "import ffmpeg\n",
    "import easyocr\n",
    "import shutil\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from ShazamAPI import Shazam\n",
    "from langdetect import detect, DetectorFactory\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"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\"\n",
    "gpt_client = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client\n",
    "\n",
    "url: str = \"https://pqhcubzkrlbvljbvsmem.supabase.co\"\n",
    "key: str = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InBxaGN1YnprcmxidmxqYnZzbWVtIiwicm9sZSI6ImFub24iLCJpYXQiOjE3Mjc4NzgyNDYsImV4cCI6MjA0MzQ1NDI0Nn0.5Yt2zMMm09II29COY58lXIvIQID1N7FM6JL3-B9jhdU\"\n",
    "supabase: Client = create_client(url, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client(\"s3\")\n",
    "\n",
    "DB_CONNECTION = \"postgresql://postgres.pqhcubzkrlbvljbvsmem:baw1mART4@aws-0-eu-west-3.pooler.supabase.com:5432/postgres\"\n",
    "DB_PASSWORD = \"baw1mART4-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_FOLDER = \"FRAMES\"\n",
    "RAW_DATA_FOLDER = \"DATA\"\n",
    "\n",
    "os.mkdir(FRAME_FOLDER)\n",
    "os.mkdir(RAW_DATA_FOLDER)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://www.youtube.com/watch?v=IA1gFD1HeQg\"  \n",
    "output_filename = f\"{RAW_DATA_FOLDER}/audio\"\n",
    "audio_filename = f\"{RAW_DATA_FOLDER}/audio.mp3\"\n",
    "output_metadata_filename=f\"{RAW_DATA_FOLDER}/video_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tiktok_audio(video_url, output_filename):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': output_filename,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "    }\n",
    "\n",
    "    with yt.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([video_url])\n",
    "\n",
    "def transcript_audio_to_text(audio_filename, is_music):\n",
    "    if is_music is False : \n",
    "        model = whisper.load_model(\"base\")\n",
    "        result = model.transcribe(audio_filename)\n",
    "        text = result[\"text\"]\n",
    "        print(f\"text : {result[\"text\"]}\")\n",
    "\n",
    "\n",
    "        return text\n",
    "    else:\n",
    "        return \"\", \" \"\n",
    "\n",
    "\n",
    "def get_tiktok_metadata(video_url, output_metadata_filename):\n",
    "    pyk.save_tiktok(video_url,\n",
    "                False,\n",
    "                output_metadata_filename)\n",
    "    \n",
    "\n",
    "def extract_metadata(output_metadata_filename):\n",
    "    data = pd.read_csv(output_metadata_filename)\n",
    "    video_author = data[\"author_username\"][0]\n",
    "    video_id = data[\"video_id\"][0]\n",
    "    video_time = data[\"video_duration\"][0]\n",
    "    video_title = f\"@{video_author}_video_{video_id}.mp4\"\n",
    "    video_description = data[\"video_description\"][0]\n",
    "    return video_title, video_description, video_time\n",
    "\n",
    "\n",
    "def download_video(video_url, output_metadata_filename, video_time):\n",
    "    if video_time <= 150:\n",
    "        pyk.save_tiktok(video_url,\n",
    "                True,\n",
    "                output_metadata_filename)\n",
    "\n",
    "\n",
    "def extract_video_frames(video_title , video_time, fps = 1):\n",
    "    if video_time > 150:\n",
    "        print(\"Video too long, no video extraction\")\n",
    "        return \n",
    "    else:\n",
    "        output_frames = f'{FRAME_FOLDER}/frame_%04d.png'\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(video_title)\n",
    "            .output(output_frames, vf=f'fps={fps}')\n",
    "            .run()\n",
    "        )\n",
    "\n",
    "        print(\"Frames extraction done.\")\n",
    "\n",
    "\n",
    "def create_reader():\n",
    "    reader = easyocr.Reader(['en','fr','es','it','de'])\n",
    "    return reader\n",
    "\n",
    "\n",
    "def extract_text_from_frames(reader, frame_folder, video_time):\n",
    "    if video_time > 150 : \n",
    "        print(\"no frame extraction\")\n",
    "        return \" \"\n",
    "    else:\n",
    "        video_frame_text = []\n",
    "        for frame in os.listdir(frame_folder):\n",
    "            result = reader.readtext(f\"{frame_folder}/{frame}\")\n",
    "            for detection in result:\n",
    "                video_frame_text.append(detection[1])\n",
    "        print( video_frame_text)\n",
    "        return video_frame_text\n",
    "\n",
    "\n",
    "def generate_input_text(video_description, video_audio, video_frame_text):\n",
    "    generated_texts = video_description , video_audio ,  \" \".join(video_frame_text)\n",
    "    print( generated_texts)\n",
    "    return generated_texts\n",
    "\n",
    "\n",
    "def forecast_places(input_generated_texts):\n",
    "    nlp = spacy.load(\"xx_ent_wiki_sm\")\n",
    "    doc = nlp(str(input_generated_texts))\n",
    "    forecasted_places = [ent.text for ent in doc.ents if ent.label_  in [\"LOC\"]]\n",
    "    print(\"forecasted places :\", forecasted_places)\n",
    "    return forecasted_places\n",
    "\n",
    "\n",
    "def check_audio(audio_file_name): \n",
    "    try:\n",
    "        with open(audio_file_name, 'rb') as audio_file:\n",
    "            mp3_file_content_to_recognize = audio_file.read()\n",
    "        \n",
    "            shazam = Shazam(mp3_file_content_to_recognize)\n",
    "            recognize_generator = shazam.recognizeSong()\n",
    "            if True:\n",
    "                print(\"Identified music.\")\n",
    "                return False\n",
    "    except FileNotFoundError:\n",
    "        print(\"No music\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error append: {e}\")\n",
    "    return False\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    text = re.sub(r'[@#]\\w+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s,.\\'â€™-]', '', text) \n",
    "    return text\n",
    "\n",
    "\n",
    "def nlp_forecast(client, text): \n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"You are usefull to seek places in a text with their city and country\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "            \"\"\"\n",
    "            Instructions:\n",
    "                - Given the text at the end, find all the places to visit quote in this text. \n",
    "                - Return the number of places you find\n",
    "                - Return the city of these places in English\n",
    "                - Return the country of these places in English\n",
    "                - Do not return the same place multiple time\n",
    "                - Return only in the python dictionary format like below\n",
    "                - Do not include any additional formatting, such as markdown code blocks\n",
    "\n",
    "\n",
    "            {\n",
    "            \"place_number\" : \"<number of places>\",\n",
    "            \"place_1\" : \"<first place you find in the text>\",\n",
    "            \"place_2\" : \"<second place you find in the text>\", \n",
    "            ...,\n",
    "            \"place_n\" : \"<the nth place you find in the text>\n",
    "            \"city\" :\" <the city of these places>\", \n",
    "            \"country\" : \"<the country of these places>\"\n",
    "             },\n",
    "\n",
    "             \n",
    "            The text could be bad formated but just focus to find similitude with the places you know \n",
    "            There is the text to analyse :\n",
    "            \"\"\" + text\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "    output = completion.choices[0].message.content\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    words = text.split()\n",
    "    seen = set()\n",
    "    unique_words = []\n",
    "    for word in words:\n",
    "        if word not in seen:\n",
    "            unique_words.append(word)\n",
    "            seen.add(word)\n",
    "    \n",
    "    return ' '.join(unique_words)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = re.sub(r\"[^\\w\\s,]\", \"\", text)\n",
    "    cleaned_text = re.sub(r\",+\", \",\", cleaned_text)\n",
    "    cleaned_text = cleaned_text.replace(\",,\", \",\")  \n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=IA1gFD1HeQg\n",
      "[youtube] IA1gFD1HeQg: Downloading webpage\n",
      "[youtube] IA1gFD1HeQg: Downloading ios player API JSON\n",
      "[youtube] IA1gFD1HeQg: Downloading web creator player API JSON\n",
      "[youtube] IA1gFD1HeQg: Downloading m3u8 information\n",
      "[info] IA1gFD1HeQg: Downloading 1 format(s): 251\n",
      "[download] Destination: DATA/audio\n",
      "[download] 100% of   87.85KiB in 00:00:00 at 414.49KiB/s \n",
      "[ExtractAudio] Destination: DATA/audio.mp3\n",
      "Deleting original file DATA/audio (pass -k to keep)\n",
      "Identified music.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/miniconda3/envs/testing/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/Users/user/miniconda3/envs/testing/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text :  TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARULA TARUL\n",
      "The function encountered a downstream error and did not deliver any data, which happens periodically for various reasons. Please try again later.\n",
      "ERROR : 'NoneType' object is not subscriptable\n",
      "\n",
      "        Oops, Something append... Are you sure this is a Instagram Reel or Tiktok Video ? \n",
      "          \n"
     ]
    }
   ],
   "source": [
    "try : \n",
    "    download_tiktok_audio(video_url, output_filename)\n",
    "    is_music = check_audio(audio_filename)\n",
    "    video_audio = transcript_audio_to_text(audio_filename, is_music)\n",
    "    get_tiktok_metadata(video_url, output_metadata_filename)\n",
    "    video_title, video_description, video_time = extract_metadata(output_metadata_filename)\n",
    "    print(f\"video time : {video_time} seconds\")\n",
    "    download_video(video_url, output_metadata_filename, video_time)\n",
    "    extract_video_frames(video_title, video_time)\n",
    "    reader = create_reader()\n",
    "    video_frame_text = extract_text_from_frames(reader, frame_folder=FRAME_FOLDER, video_time=video_time)\n",
    "    input_text = generate_input_text(video_description, video_audio, video_frame_text)\n",
    "    cleaned_text = clean_text(str(input_text))\n",
    "    print(\"cleaned text : \" + cleaned_text)\n",
    "except Exception as e:\n",
    "    print(\"ERROR : \" + str(e))\n",
    "\n",
    "    print(\"\"\"\n",
    "        Oops, Something append... Are you sure this is a Instagram Reel or Tiktok Video ? \n",
    "          \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 places you NEED to visit in Berlin Save this for when DARK MATTER Reichstag Building East Side Gallery Holocaust Memorial Checkpoint Charlie berlin germany, things do, travel, travel contwnt creator,  Okay, 5 hings do part 1 Dark Matter savethis post 3East save 1 4 sqvethfs 2 p 5o AUEO ODMV\n"
     ]
    }
   ],
   "source": [
    "new = remove_duplicates(cleaned_text)\n",
    "new = preprocess_text(new)\n",
    "\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 places you NEED to visit in Berlin Save this for when DARK MATTER Reichstag Building East Side Gallery Holocaust Memorial Checkpoint Charlie berlin germany, things do, travel, travel contwnt creator,  Okay, 5 hings do part 1 Dark Matter savethis post 3East save 1 4 sqvethfs 2 p 5o AUEO ODMV\n",
      "{\n",
      "\"place_number\" : \"5\",\n",
      "\"place_1\" : \"DARK MATTER\",\n",
      "\"place_2\" : \"Reichstag Building\",\n",
      "\"place_3\" : \"East Side Gallery\",\n",
      "\"place_4\" : \"Holocaust Memorial\",\n",
      "\"place_5\" : \"Checkpoint Charlie\",\n",
      "\"city\" :\"Berlin\",\n",
      "\"country\" : \"Germany\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_number</th>\n",
       "      <th>place_1</th>\n",
       "      <th>place_2</th>\n",
       "      <th>place_3</th>\n",
       "      <th>place_4</th>\n",
       "      <th>place_5</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>DARK MATTER</td>\n",
       "      <td>Reichstag Building</td>\n",
       "      <td>East Side Gallery</td>\n",
       "      <td>Holocaust Memorial</td>\n",
       "      <td>Checkpoint Charlie</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  place_number      place_1             place_2            place_3  \\\n",
       "0            5  DARK MATTER  Reichstag Building  East Side Gallery   \n",
       "\n",
       "              place_4             place_5    city  country  \n",
       "0  Holocaust Memorial  Checkpoint Charlie  Berlin  Germany  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(new)\n",
    "output = nlp_forecast(gpt_client, str(input_text))\n",
    "dico = eval(output)\n",
    "data = pd.DataFrame(dico, index=[0])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = int(data[\"place_number\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def upload_raw_to_supabase(video_url, video_description, video_frame_text,video_audio,cleaned_text,data,list_of_places):\n",
    "    list_of_places = []\n",
    "    for i in range(1, pn+1):\n",
    "        list_of_places.append(data[f\"place_{i}\"][0])\n",
    "    response = (\n",
    "        supabase.table(\"generated_text\")\n",
    "        .insert({\n",
    "            \"video_url\": video_url,\n",
    "            \"video_description_text\" : video_description,\n",
    "            \"video_frame_text\" : video_frame_text ,\n",
    "            \"video_audio_text\" : video_audio,\n",
    "            \"video_cleaned_text\" : cleaned_text,\n",
    "            \"place_number\" : int(data[\"place_number\"][0]),\n",
    "            \"place_city\" : data[\"city\"][0],\n",
    "            \"place_country\" : data[\"country\"][0],\n",
    "            \"output\" : list_of_places\n",
    "            })\n",
    "        .execute()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(FRAME_FOLDER)\n",
    "shutil.rmtree(RAW_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = 'AIzaSyCo-rjmf08Vh4sRAXdyW1Ll92ykDTHCkE4'\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def get_place_details(place_name: list, nplace: int):\n",
    "    # Initialisation de la liste pour stocker les informations des lieux\n",
    "    place_informations_list = []\n",
    "    \n",
    "    for n in range(nplace):\n",
    "        url = f\"https://maps.googleapis.com/maps/api/place/textsearch/json?query={place_name[n]}&key={API_KEY}\"\n",
    "        response = requests.get(url)\n",
    "        results = response.json().get('results', [])\n",
    "        \n",
    "        if results:\n",
    "            place = results[0]\n",
    "            place_id = place['place_id']\n",
    "            \n",
    "            # RequÃªte pour obtenir les dÃ©tails du lieu\n",
    "            details_url = f\"https://maps.googleapis.com/maps/api/place/details/json?place_id={place_id}&key={API_KEY}\"\n",
    "            details_response = requests.get(details_url)\n",
    "            details = details_response.json().get('result', {})\n",
    "            \n",
    "            # Extraction des informations nÃ©cessaires\n",
    "            name = details.get('name')\n",
    "            address = details.get('formatted_address')\n",
    "            html_adress = details.get(\"adr_address\")\n",
    "            types = details.get('types')\n",
    "            user_rating = details.get('user_ratings_total')\n",
    "            rating = details.get('rating')\n",
    "            \n",
    "            # Stocker les informations sous forme de dictionnaire\n",
    "            current_informations = {\n",
    "                \"Name\": name,\n",
    "                \"Address\": address,\n",
    "                \"HTML_address\" : html_adress,\n",
    "                \"Types\": types,\n",
    "                \"Rating_count\": user_rating,\n",
    "                \"Rate\": rating\n",
    "            }\n",
    "            \n",
    "            # Ajouter les informations Ã  la liste\n",
    "            place_informations_list.append(current_informations)\n",
    "            \n",
    "            # Affichage des informations\n",
    "            print(f\"Name_{n}:\", name)\n",
    "            print(f\"Address_{n}:\", address)\n",
    "            print(f\"Types_{n}:\", types)\n",
    "            print(f\"User ratings total_{n}:\", user_rating)\n",
    "            print(f\"Rating_{n}:\", rating)\n",
    "            print(\"\"\" \n",
    "                  \n",
    "                  -------- \n",
    "                  \n",
    "                  \"\"\")\n",
    "        else:\n",
    "            print(f\"No place found for '{place_name[n]}'.\")\n",
    "\n",
    "    # CrÃ©er un DataFrame Ã  partir de la liste de dictionnaires\n",
    "    place_informations = pd.DataFrame(place_informations_list)\n",
    "    \n",
    "    return place_informations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DARK MATTER Berlin Germany', 'Reichstag Building Berlin Germany', 'East Side Gallery Berlin Germany', 'Holocaust Memorial Berlin Germany', 'Checkpoint Charlie Berlin Germany']\n"
     ]
    }
   ],
   "source": [
    "research_places = []\n",
    "for n in range(1, pn+1):\n",
    "    formated_adress = data[f\"place_{n}\"][0] +\" \"+ data[\"city\"][0] +\" \"+ data[\"country\"][0]\n",
    "    research_places.append(formated_adress)\n",
    "\n",
    "print(research_places)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name_0: DARK MATTER\n",
      "Address_0: KÃ¶penicker Ch 46, 10317 Berlin, Germany\n",
      "Types_0: ['museum', 'point_of_interest', 'establishment']\n",
      "User ratings total_0: 4112\n",
      "Rating_0: 4.5\n",
      " \n",
      "                  \n",
      "                  -------- \n",
      "                  \n",
      "                  \n",
      "Name_1: Reichstag Building\n",
      "Address_1: Platz der Republik 1, 11011 Berlin, Germany\n",
      "Types_1: ['tourist_attraction', 'point_of_interest', 'establishment']\n",
      "User ratings total_1: 8617\n",
      "Rating_1: 4.7\n",
      " \n",
      "                  \n",
      "                  -------- \n",
      "                  \n",
      "                  \n",
      "Name_2: East Side Gallery\n",
      "Address_2: MÃ¼hlenstraÃŸe, 10243 Berlin, Germany\n",
      "Types_2: ['landmark', 'art_gallery', 'tourist_attraction', 'point_of_interest', 'establishment']\n",
      "User ratings total_2: 56013\n",
      "Rating_2: 4.6\n",
      " \n",
      "                  \n",
      "                  -------- \n",
      "                  \n",
      "                  \n",
      "Name_3: Memorial to the Murdered Jews of Europe\n",
      "Address_3: Cora-Berliner-StraÃŸe 1, 10117 Berlin, Germany\n",
      "Types_3: ['tourist_attraction', 'point_of_interest', 'establishment']\n",
      "User ratings total_3: 46323\n",
      "Rating_3: 4.6\n",
      " \n",
      "                  \n",
      "                  -------- \n",
      "                  \n",
      "                  \n",
      "Name_4: Checkpoint Charlie\n",
      "Address_4: FriedrichstraÃŸe 43-45, 10117 Berlin, Germany\n",
      "Types_4: ['tourist_attraction', 'point_of_interest', 'establishment']\n",
      "User ratings total_4: 85490\n",
      "Rating_4: 4.1\n",
      " \n",
      "                  \n",
      "                  -------- \n",
      "                  \n",
      "                  \n"
     ]
    }
   ],
   "source": [
    "referenced_dataframe = get_place_details(research_places, len(research_places))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>HTML_address</th>\n",
       "      <th>Types</th>\n",
       "      <th>Rating_count</th>\n",
       "      <th>Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DARK MATTER</td>\n",
       "      <td>KÃ¶penicker Ch 46, 10317 Berlin, Germany</td>\n",
       "      <td>&lt;span class=\"street-address\"&gt;KÃ¶penicker Ch 46&lt;/span&gt;, &lt;span class=\"postal-code\"&gt;10317&lt;/span&gt; &lt;span class=\"locality\"&gt;Berlin&lt;/span&gt;, &lt;span class=\"country-name\"&gt;Germany&lt;/span&gt;</td>\n",
       "      <td>[museum, point_of_interest, establishment]</td>\n",
       "      <td>4112</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reichstag Building</td>\n",
       "      <td>Platz der Republik 1, 11011 Berlin, Germany</td>\n",
       "      <td>&lt;span class=\"street-address\"&gt;Platz der Republik 1&lt;/span&gt;, &lt;span class=\"postal-code\"&gt;11011&lt;/span&gt; &lt;span class=\"locality\"&gt;Berlin&lt;/span&gt;, &lt;span class=\"country-name\"&gt;Germany&lt;/span&gt;</td>\n",
       "      <td>[tourist_attraction, point_of_interest, establishment]</td>\n",
       "      <td>8617</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>East Side Gallery</td>\n",
       "      <td>MÃ¼hlenstraÃŸe, 10243 Berlin, Germany</td>\n",
       "      <td>&lt;span class=\"street-address\"&gt;MÃ¼hlenstraÃŸe&lt;/span&gt;, &lt;span class=\"postal-code\"&gt;10243&lt;/span&gt; &lt;span class=\"locality\"&gt;Berlin&lt;/span&gt;, &lt;span class=\"country-name\"&gt;Germany&lt;/span&gt;</td>\n",
       "      <td>[landmark, art_gallery, tourist_attraction, point_of_interest, establishment]</td>\n",
       "      <td>56013</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Memorial to the Murdered Jews of Europe</td>\n",
       "      <td>Cora-Berliner-StraÃŸe 1, 10117 Berlin, Germany</td>\n",
       "      <td>&lt;span class=\"street-address\"&gt;Cora-Berliner-StraÃŸe 1&lt;/span&gt;, &lt;span class=\"postal-code\"&gt;10117&lt;/span&gt; &lt;span class=\"locality\"&gt;Berlin&lt;/span&gt;, &lt;span class=\"country-name\"&gt;Germany&lt;/span&gt;</td>\n",
       "      <td>[tourist_attraction, point_of_interest, establishment]</td>\n",
       "      <td>46323</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Checkpoint Charlie</td>\n",
       "      <td>FriedrichstraÃŸe 43-45, 10117 Berlin, Germany</td>\n",
       "      <td>&lt;span class=\"street-address\"&gt;FriedrichstraÃŸe 43-45&lt;/span&gt;, &lt;span class=\"postal-code\"&gt;10117&lt;/span&gt; &lt;span class=\"locality\"&gt;Berlin&lt;/span&gt;, &lt;span class=\"country-name\"&gt;Germany&lt;/span&gt;</td>\n",
       "      <td>[tourist_attraction, point_of_interest, establishment]</td>\n",
       "      <td>85490</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name  \\\n",
       "0                              DARK MATTER   \n",
       "1                       Reichstag Building   \n",
       "2                        East Side Gallery   \n",
       "3  Memorial to the Murdered Jews of Europe   \n",
       "4                       Checkpoint Charlie   \n",
       "\n",
       "                                         Address  \\\n",
       "0        KÃ¶penicker Ch 46, 10317 Berlin, Germany   \n",
       "1    Platz der Republik 1, 11011 Berlin, Germany   \n",
       "2            MÃ¼hlenstraÃŸe, 10243 Berlin, Germany   \n",
       "3  Cora-Berliner-StraÃŸe 1, 10117 Berlin, Germany   \n",
       "4   FriedrichstraÃŸe 43-45, 10117 Berlin, Germany   \n",
       "\n",
       "                                                                                                                                                                         HTML_address  \\\n",
       "0        <span class=\"street-address\">KÃ¶penicker Ch 46</span>, <span class=\"postal-code\">10317</span> <span class=\"locality\">Berlin</span>, <span class=\"country-name\">Germany</span>   \n",
       "1    <span class=\"street-address\">Platz der Republik 1</span>, <span class=\"postal-code\">11011</span> <span class=\"locality\">Berlin</span>, <span class=\"country-name\">Germany</span>   \n",
       "2            <span class=\"street-address\">MÃ¼hlenstraÃŸe</span>, <span class=\"postal-code\">10243</span> <span class=\"locality\">Berlin</span>, <span class=\"country-name\">Germany</span>   \n",
       "3  <span class=\"street-address\">Cora-Berliner-StraÃŸe 1</span>, <span class=\"postal-code\">10117</span> <span class=\"locality\">Berlin</span>, <span class=\"country-name\">Germany</span>   \n",
       "4   <span class=\"street-address\">FriedrichstraÃŸe 43-45</span>, <span class=\"postal-code\">10117</span> <span class=\"locality\">Berlin</span>, <span class=\"country-name\">Germany</span>   \n",
       "\n",
       "                                                                           Types  \\\n",
       "0                                     [museum, point_of_interest, establishment]   \n",
       "1                         [tourist_attraction, point_of_interest, establishment]   \n",
       "2  [landmark, art_gallery, tourist_attraction, point_of_interest, establishment]   \n",
       "3                         [tourist_attraction, point_of_interest, establishment]   \n",
       "4                         [tourist_attraction, point_of_interest, establishment]   \n",
       "\n",
       "   Rating_count  Rate  \n",
       "0          4112   4.5  \n",
       "1          8617   4.7  \n",
       "2         56013   4.6  \n",
       "3         46323   4.6  \n",
       "4         85490   4.1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "referenced_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(referenced_dataframe)):\n",
    "    response = (\n",
    "        supabase.table(\"referenced_places\")\n",
    "        .insert({\n",
    "            \"video_url\": video_url,\n",
    "            \"place_name\" : referenced_dataframe[\"Name\"][n],\n",
    "            \"place_address\" : referenced_dataframe[\"Address\"][n],\n",
    "            \"place_html_address\" : referenced_dataframe[\"HTML_address\"][n],\n",
    "            \"place_types\" : referenced_dataframe[\"Types\"][n],\n",
    "            \"place_rating_count\" : int(referenced_dataframe[\"Rating_count\"][n]),\n",
    "            \"place_rate\" : float(referenced_dataframe[\"Rate\"][n]),\n",
    "            \"place_city\" : data[\"city\"][0],\n",
    "            \"place_country\" : data[\"country\"][0],\n",
    "            })\n",
    "        .execute()\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
