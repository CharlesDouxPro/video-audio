{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp as yt\n",
    "import whisper\n",
    "import pyktok as pyk\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import spacy\n",
    "import os\n",
    "import ffmpeg\n",
    "import easyocr\n",
    "import shutil\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from ShazamAPI import Shazam\n",
    "from langdetect import detect, DetectorFactory\n",
    "import re\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"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\"\n",
    "gpt_client = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client\n",
    "\n",
    "url: str = \"https://pqhcubzkrlbvljbvsmem.supabase.co\"\n",
    "key: str = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InBxaGN1YnprcmxidmxqYnZzbWVtIiwicm9sZSI6ImFub24iLCJpYXQiOjE3Mjc4NzgyNDYsImV4cCI6MjA0MzQ1NDI0Nn0.5Yt2zMMm09II29COY58lXIvIQID1N7FM6JL3-B9jhdU\"\n",
    "supabase: Client = create_client(url, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client(\"s3\")\n",
    "\n",
    "DB_CONNECTION = \"postgresql://postgres.pqhcubzkrlbvljbvsmem:baw1mART4@aws-0-eu-west-3.pooler.supabase.com:5432/postgres\"\n",
    "DB_PASSWORD = \"baw1mART4-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_FOLDER = \"FRAMES\"\n",
    "RAW_DATA_FOLDER = \"DATA\"\n",
    "\n",
    "os.mkdir(FRAME_FOLDER)\n",
    "os.mkdir(RAW_DATA_FOLDER)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://www.tiktok.com/@sashazhoyaofficial/video/7372174468665347361?is_from_webapp=1&sender_device=pc&web_id=7423833413503174176\"  \n",
    "output_filename = f\"{RAW_DATA_FOLDER}/audio\"\n",
    "audio_filename = f\"{RAW_DATA_FOLDER}/audio.mp3\"\n",
    "output_metadata_filename=f\"{RAW_DATA_FOLDER}/video_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tiktok_audio(video_url, output_filename):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': output_filename,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "    }\n",
    "\n",
    "    with yt.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([video_url])\n",
    "\n",
    "def transcript_audio_to_text(audio_filename, is_music):\n",
    "    if is_music is False : \n",
    "        model = whisper.load_model(\"base\")\n",
    "        result = model.transcribe(audio_filename)\n",
    "        text = result[\"text\"]\n",
    "        print(f\"text : {result[\"text\"]}\")\n",
    "\n",
    "\n",
    "        return text\n",
    "    else:\n",
    "        return \"\", \" \"\n",
    "\n",
    "\n",
    "def get_tiktok_metadata(video_url, output_metadata_filename):\n",
    "    pyk.save_tiktok(video_url,\n",
    "                False,\n",
    "                output_metadata_filename)\n",
    "    \n",
    "\n",
    "def extract_metadata(output_metadata_filename):\n",
    "    data = pd.read_csv(output_metadata_filename)\n",
    "    video_author = data[\"author_username\"][0]\n",
    "    video_id = data[\"video_id\"][0]\n",
    "    video_time = data[\"video_duration\"][0]\n",
    "    video_title = f\"@{video_author}_video_{video_id}.mp4\"\n",
    "    video_description = data[\"video_description\"][0]\n",
    "    return video_title, video_description, video_time\n",
    "\n",
    "\n",
    "def download_video(video_url, output_metadata_filename, video_time):\n",
    "    if video_time <= 150:\n",
    "        pyk.save_tiktok(video_url,\n",
    "                True,\n",
    "                output_metadata_filename)\n",
    "\n",
    "\n",
    "def extract_video_frames(video_title , video_time, fps = 1):\n",
    "    if video_time > 150:\n",
    "        print(\"Video too long, no video extraction\")\n",
    "        return \n",
    "    else:\n",
    "        output_frames = f'{FRAME_FOLDER}/frame_%04d.png'\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(video_title)\n",
    "            .output(output_frames, vf=f'fps={fps}')\n",
    "            .run()\n",
    "        )\n",
    "\n",
    "        print(\"Frames extraction done.\")\n",
    "\n",
    "\n",
    "def create_reader():\n",
    "    reader = easyocr.Reader(['en','fr','es','it','de'])\n",
    "    return reader\n",
    "\n",
    "\n",
    "def extract_text_from_frames(reader, frame_folder, video_time):\n",
    "    if video_time > 150 : \n",
    "        print(\"no frame extraction\")\n",
    "        return \" \"\n",
    "    else:\n",
    "        video_frame_text = []\n",
    "        for frame in os.listdir(frame_folder):\n",
    "            result = reader.readtext(f\"{frame_folder}/{frame}\")\n",
    "            for detection in result:\n",
    "                video_frame_text.append(detection[1])\n",
    "        print( video_frame_text)\n",
    "        return video_frame_text\n",
    "\n",
    "\n",
    "def generate_input_text(video_description, video_audio, video_frame_text):\n",
    "    generated_texts = video_description , video_audio ,  \" \".join(video_frame_text)\n",
    "    print( generated_texts)\n",
    "    return generated_texts\n",
    "\n",
    "\n",
    "def forecast_places(input_generated_texts):\n",
    "    nlp = spacy.load(\"xx_ent_wiki_sm\")\n",
    "    doc = nlp(str(input_generated_texts))\n",
    "    forecasted_places = [ent.text for ent in doc.ents if ent.label_  in [\"LOC\"]]\n",
    "    print(\"forecasted places :\", forecasted_places)\n",
    "    return forecasted_places\n",
    "\n",
    "\n",
    "def check_audio(audio_file_name): \n",
    "    try:\n",
    "        with open(audio_file_name, 'rb') as audio_file:\n",
    "            mp3_file_content_to_recognize = audio_file.read()\n",
    "        \n",
    "            shazam = Shazam(mp3_file_content_to_recognize)\n",
    "            recognize_generator = shazam.recognizeSong()\n",
    "            if True:\n",
    "                print(\"Identified music.\")\n",
    "                return False\n",
    "    except FileNotFoundError:\n",
    "        print(\"No music\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error append: {e}\")\n",
    "    return False\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    text = re.sub(r'[@#]\\w+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s,.\\'’-]', '', text) \n",
    "    return text\n",
    "\n",
    "\n",
    "def nlp_forecast(client, text): \n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"You are usefull to seek places in a text with their city and country\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "            \"\"\"\n",
    "            Instructions:\n",
    "                - Given the text at the end, find all the places to visit quote in this text. \n",
    "                - Return the number of places you find\n",
    "                - Return the city of these places in English\n",
    "                - Return the country of these places in English\n",
    "                - Do not return the same place multiple time\n",
    "                - Return only in the python dictionary format like below\n",
    "                - Do not include any additional formatting, such as markdown code blocks\n",
    "\n",
    "\n",
    "            {\n",
    "            \"place_number\" : \"<number of places>\",\n",
    "            \"place_1\" : \"<first place you find in the text>\",\n",
    "            \"place_2\" : \"<second place you find in the text>\", \n",
    "            ...,\n",
    "            \"place_n\" : \"<the nth place you find in the text>\n",
    "            \"city\" :\" <the city of these places>\", \n",
    "            \"country\" : \"<the country of these places>\"\n",
    "             },\n",
    "\n",
    "             \n",
    "            The text could be bad formated but just focus to find similitude with the places you know \n",
    "            There is the text to analyse :\n",
    "            \"\"\" + text\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "    output = completion.choices[0].message.content\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    words = text.split()\n",
    "    seen = set()\n",
    "    unique_words = []\n",
    "    for word in words:\n",
    "        if word not in seen:\n",
    "            unique_words.append(word)\n",
    "            seen.add(word)\n",
    "    \n",
    "    return ' '.join(unique_words)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = re.sub(r\"[^\\w\\s,]\", \"\", text)\n",
    "    cleaned_text = re.sub(r\",+\", \",\", cleaned_text)\n",
    "    cleaned_text = cleaned_text.replace(\",,\", \",\")  \n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TikTok] Extracting URL: https://www.tiktok.com/@sashazhoyaofficial/video/7372174468665347361?is_from_webapp=1&sender_devi...=7423833413503174176\n",
      "[TikTok] 7372174468665347361: Downloading webpage\n",
      "[info] 7372174468665347361: Downloading 1 format(s): bytevc1_1080p_720687-1\n",
      "[download] Destination: DATA/audio\n",
      "[download] 100% of    7.31MiB in 00:00:00 at 7.61MiB/s     \n",
      "[ExtractAudio] Destination: DATA/audio.mp3\n",
      "Deleting original file DATA/audio (pass -k to keep)\n",
      "Identified music.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/miniconda3/envs/testing/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/Users/user/miniconda3/envs/testing/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text :  En 2 000 finales de ces championnats du monde, tu te propres encore personnels sur cette taille là, 1-0-6. 13 secondes 15 centièmes. Le record du monde, c'est à 12.8 à quel point tu vois genre, c'est inaténiable entre guillemets, à quel point comment tu vois ça. C'est que pour nous, j'allais dire les humains un peu normaux, tu veux dire genre... C'est justement un des détails, etc. Comment ? Oui, comment ? Je vois ça, ça joue à des détails, mais pour moi, dans ma tête, comme j'ai déjà fait en dessous ce chrono, mais c'est dans un taille junior, avec les mains plus basses. Et le même truc que tu vois j'ai fait, soit son 12, ça me dit que sur la même hauteur à 0-6, je pourrais passer en dessous les 80, mais ça m'a pas du temps. Est-ce que du coup, tu as fait 12 secondes, de 72, on voyait le record sur des A2, quel taille ? 99 centièmes. Ouais, donc c'était un taille plus petite, mais... On sera actuellement actuellement. On logique, il faudra actuellement actuellement actuellement. Tu l'as cette vitesse, t'en sais que moi, je suis en vitesse en écoquence. C'est ça qu'on interpe.\n",
      "Saved metadata for video\n",
      " https://www.tiktok.com/@sashazhoyaofficial/video/7372174468665347361?is_from_webapp=1&sender_device=pc&web_id=7423833413503174176 \n",
      "to\n",
      " /Users/user/Documents/ProjetIATiktok\n",
      "video time : 85 seconds\n",
      "Saved video\n",
      " https://www.tiktok.com/@sashazhoyaofficial/video/7372174468665347361?is_from_webapp=1&sender_device=pc&web_id=7423833413503174176 \n",
      "to\n",
      " /Users/user/Documents/ProjetIATiktok\n",
      "Saved metadata for video\n",
      " https://www.tiktok.com/@sashazhoyaofficial/video/7372174468665347361?is_from_webapp=1&sender_device=pc&web_id=7423833413503174176 \n",
      "to\n",
      " /Users/user/Documents/ProjetIATiktok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.0.2_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '@sashazhoyaofficial_video_7372174468665347361.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    comment         : vid:v0f044gc0000cp7iugvog65lda6kkpl0\n",
      "    aigc_info       : {\"aigc_label_type\": 0}\n",
      "    vid_md5         : 94203df8cd159f58fe322e85a26bdfb8\n",
      "    encoder         : Lavf58.76.100\n",
      "  Duration: 00:01:25.13, start: 0.000000, bitrate: 1026 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 576x1024 [SAR 1:1 DAR 9:16], 988 kb/s, 29.21 fps, 30 tbr, 15360 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](und): Audio: aac (HE-AACv2) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 32 kb/s (default)\n",
      "      Metadata:\n",
      "        handler_name    : SoundHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128400000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128410000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128420000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128430000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128440000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128450000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128460000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128470000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128480000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "Output #0, image2, to 'FRAMES/frame_%04d.png':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    comment         : vid:v0f044gc0000cp7iugvog65lda6kkpl0\n",
      "    aigc_info       : {\"aigc_label_type\": 0}\n",
      "    vid_md5         : 94203df8cd159f58fe322e85a26bdfb8\n",
      "    encoder         : Lavf61.1.100\n",
      "  Stream #0:0(und): Video: png, rgb24(pc, gbr/bt709/bt709, progressive), 576x1024 [SAR 1:1 DAR 9:16], q=2-31, 200 kb/s, 1 fps, 1 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.3.100 png\n",
      "[out#0/image2 @ 0x148021590] video:43880KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: unknown\n",
      "frame=   85 fps= 72 q=-0.0 Lsize=N/A time=00:01:25.00 bitrate=N/A speed=71.9x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames extraction done.\n",
      "['MAISDOUR M@I', 'français', 'GENRE @EST', '[NATTEIGNABLE', 'français', 'ENTRE GUILLEMETS', 'français', 'eDF', 'PUISQUENENDEMF', 'FINA4B', 'françals', 'ep', 'G@MME JAIDeJà', 'français', 'TEAM', 'français', 'PROPRE RECORD', 'PERSONNED', 'françals', 'DUM@NDE', 'françals', '@OMMENT', 'françals', 'à @UELPOINT', 'français', 'français', 'POPCORN', '13.15S', 'français', 'à @UEL POINT', 'français', 'D@NG 1@6GM', 'français', 'eDF', '128', 'français', 'co', '1-06CM JE', 'POPCORN ', 'Sasha Zhoya', \"La nouvelle péplte de l'athlét\", 'TeaN', 'MêMEHAUTEUR', 'français', 'IEAM', 'PoPCorn', 'LE RECORD DU', 'français', 'SURGTTBTAI4E', '4A', 'français', 'TEAM', 'eDF', '14e777', 'BS', 'Hordl', 'Eiics', '#TDI', 'HIko', 'PIKO', '78K', '8G', '#TDK', 'HKO', 'ZIKC', '0', 'd51l', 'OK', 'TDK', '@UAIS', 'français', '@KAM', 'eDF', '0', 'Zhoy', 'FrANCE _', '22', 'GoKDelivels', 'TDI', 'IK', 'live', '0=', 'TDK', 'er', \"DONC C'éTAIT EUH\", 'POPCORN', 'Sasha Zhoya', 'La nouvelle péplte de lathlétl', 'Teak', 'SEIKO', 'SEIKO', '5.3', 'SFt', 'T82', 'Worlo Athletics Under 20 Championships', '{', 'français', 'TEAM', 'eDF', 'SEIKO', '3', 'ONPS', '21', 'sa', 'FAthLETIC', 'CHAMPIC', '7aizobi', 'SEIKO', 'SEIKC', 'AIROBI CITY COUNTY', 'SEIK', 'SEIKO', 'ADo', 'FraNCE', 'SEIKO', 'Salcacom', 'ZHOYA', 'Zhoy', 'AM', 'eof', 'C@UP', 'POPCORN ', 'Sasha Zhoya', \"La nouvelle péplte de l'athlét\", 'VITESSEEUHPUTAIN', 'françals', 'Sulonenw', 'ZHOYA', 'ZoYA', 'FRANL', 'FRANCE', 'Soloncom', 'ZHOYA', 'NA ooe', 'Znoya', 'GETTE VITESSBEN', 'françals', 'D@NC TAVAIS FAIT', 'français', 'ATI', 'WORLD', 'TULYAS@ETTB', 'français', 'MAIS çA VA', 'POPCORN ', 'Sasha Zhoya', \"La nouvelle péplte de l'athlét\", '7', 'FranCE', 'Taat', '€', 'C', 'FRANCE', \"'Salaricom\", 'WoAnr', 'POURRAIS DASSER', 'EN', 'POPCORN ', 'Sasha Zhoya', \"La nouvelle péplte de l'athlét\", 'Tean', '4A MêME COURSB', 'françals', 'Ax', 'ed', 'TAILLE PZUS PETITE', 'POPCORN', 'Sasha Zhoya', 'La nouvelle péplte de lathlétl', '1272', 'françals', 'FrancC', '21', 'FrancE', '21', 'ZHOYA', 'mova', '@ELERECORD', 'françals', 'Teak', 'cV', 'SERA HABITUé', 'MAINTENANT', 'POPCORN', 'Sasha Zhoya', 'La nouvelle péplte de lathlétl', 'TAILLEDE99', 'français', 'eDf', 'ET APReS TU', 'français', '90121', 'prance', 'Vaac', 'ao', 'FRANCE', 'Her', 'ENL@GIQUE', 'POPCORN', 'Sasha Zhoya', 'La nouvelle péplte de lathlétl', 'HAESDE @0EL4E', 'français', 'eDF', 'POPCORN', 'français', 'GENRE çA JOUE', 'PCORN', 'Sasha Zhoya', 'La nouvelle péplte de lathlétlsme fr', 'V@iS JAIFAIT', 'français', 'TEAM', 'HAIS@T@@', 'français', '<eDF', 'QUE JE VEUX', 'Popcorn', '13.15S', 'français', '4 er', '72', 'français', 'TEAK', 'Sca', 'DéTAILS ET CETERA', 'françals', 'français', 'F', 'çA MEDIT', 'français', 'TEAM', 'HaIS @72E', 'français', 'TEAM', 'An', 'MAIS P@UR MOI', 'POPCORN', 'Sasha Zhoya', 'La nouvelle péplte de lathléti', 'cor', '0', 'DES DéTAIZS', 'POPCORN', 'Sasha Zhoya', 'La nouvelle péplte de lathléti', 'JUNI@RDF', 'français', 'IEAM', 'C@MMENTEUH', '@UAIS', 'français', 'FAIT EN DESS@US', 'français', 'P@UR N@US', 'français', '&eDF', 'HUMAINS 1PEU', \"MêME SI G'eTAIT\", 'français', 'français']\n",
      "('With @Domingo x @EDF talking records and logistics 🧐 #roadtoparis #ChampionsTalk #sportstiktok #proathlete #podcast ', \" En 2 000 finales de ces championnats du monde, tu te propres encore personnels sur cette taille là, 1-0-6. 13 secondes 15 centièmes. Le record du monde, c'est à 12.8 à quel point tu vois genre, c'est inaténiable entre guillemets, à quel point comment tu vois ça. C'est que pour nous, j'allais dire les humains un peu normaux, tu veux dire genre... C'est justement un des détails, etc. Comment ? Oui, comment ? Je vois ça, ça joue à des détails, mais pour moi, dans ma tête, comme j'ai déjà fait en dessous ce chrono, mais c'est dans un taille junior, avec les mains plus basses. Et le même truc que tu vois j'ai fait, soit son 12, ça me dit que sur la même hauteur à 0-6, je pourrais passer en dessous les 80, mais ça m'a pas du temps. Est-ce que du coup, tu as fait 12 secondes, de 72, on voyait le record sur des A2, quel taille ? 99 centièmes. Ouais, donc c'était un taille plus petite, mais... On sera actuellement actuellement. On logique, il faudra actuellement actuellement actuellement. Tu l'as cette vitesse, t'en sais que moi, je suis en vitesse en écoquence. C'est ça qu'on interpe.\", \"MAISDOUR M@I français GENRE @EST [NATTEIGNABLE français ENTRE GUILLEMETS français eDF PUISQUENENDEMF FINA4B françals ep G@MME JAIDeJà français TEAM français PROPRE RECORD PERSONNED françals DUM@NDE françals @OMMENT françals à @UELPOINT français français POPCORN 13.15S français à @UEL POINT français D@NG 1@6GM français eDF 128 français co 1-06CM JE POPCORN  Sasha Zhoya La nouvelle péplte de l'athlét TeaN MêMEHAUTEUR français IEAM PoPCorn LE RECORD DU français SURGTTBTAI4E 4A français TEAM eDF 14e777 BS Hordl Eiics #TDI HIko PIKO 78K 8G #TDK HKO ZIKC 0 d51l OK TDK @UAIS français @KAM eDF 0 Zhoy FrANCE _ 22 GoKDelivels TDI IK live 0= TDK er DONC C'éTAIT EUH POPCORN Sasha Zhoya La nouvelle péplte de lathlétl Teak SEIKO SEIKO 5.3 SFt T82 Worlo Athletics Under 20 Championships { français TEAM eDF SEIKO 3 ONPS 21 sa FAthLETIC CHAMPIC 7aizobi SEIKO SEIKC AIROBI CITY COUNTY SEIK SEIKO ADo FraNCE SEIKO Salcacom ZHOYA Zhoy AM eof C@UP POPCORN  Sasha Zhoya La nouvelle péplte de l'athlét VITESSEEUHPUTAIN françals Sulonenw ZHOYA ZoYA FRANL FRANCE Soloncom ZHOYA NA ooe Znoya GETTE VITESSBEN françals D@NC TAVAIS FAIT français ATI WORLD TULYAS@ETTB français MAIS çA VA POPCORN  Sasha Zhoya La nouvelle péplte de l'athlét 7 FranCE Taat € C FRANCE 'Salaricom WoAnr POURRAIS DASSER EN POPCORN  Sasha Zhoya La nouvelle péplte de l'athlét Tean 4A MêME COURSB françals Ax ed TAILLE PZUS PETITE POPCORN Sasha Zhoya La nouvelle péplte de lathlétl 1272 françals FrancC 21 FrancE 21 ZHOYA mova @ELERECORD françals Teak cV SERA HABITUé MAINTENANT POPCORN Sasha Zhoya La nouvelle péplte de lathlétl TAILLEDE99 français eDf ET APReS TU français 90121 prance Vaac ao FRANCE Her ENL@GIQUE POPCORN Sasha Zhoya La nouvelle péplte de lathlétl HAESDE @0EL4E français eDF POPCORN français GENRE çA JOUE PCORN Sasha Zhoya La nouvelle péplte de lathlétlsme fr V@iS JAIFAIT français TEAM HAIS@T@@ français <eDF QUE JE VEUX Popcorn 13.15S français 4 er 72 français TEAK Sca DéTAILS ET CETERA françals français F çA MEDIT français TEAM HaIS @72E français TEAM An MAIS P@UR MOI POPCORN Sasha Zhoya La nouvelle péplte de lathléti cor 0 DES DéTAIZS POPCORN Sasha Zhoya La nouvelle péplte de lathléti JUNI@RDF français IEAM C@MMENTEUH @UAIS français FAIT EN DESS@US français P@UR N@US français &eDF HUMAINS 1PEU MêME SI G'eTAIT français français\")\n",
      "cleaned text : 'With  x  talking records and logistics       ',  En 2 000 finales de ces championnats du monde, tu te propres encore personnels sur cette taille l, 1-0-6. 13 secondes 15 centimes. Le record du monde, c'est  12.8  quel point tu vois genre, c'est inatniable entre guillemets,  quel point comment tu vois a. C'est que pour nous, j'allais dire les humains un peu normaux, tu veux dire genre... C'est justement un des dtails, etc. Comment  Oui, comment  Je vois a, a joue  des dtails, mais pour moi, dans ma tte, comme j'ai dj fait en dessous ce chrono, mais c'est dans un taille junior, avec les mains plus basses. Et le mme truc que tu vois j'ai fait, soit son 12, a me dit que sur la mme hauteur  0-6, je pourrais passer en dessous les 80, mais a m'a pas du temps. Est-ce que du coup, tu as fait 12 secondes, de 72, on voyait le record sur des A2, quel taille  99 centimes. Ouais, donc c'tait un taille plus petite, mais... On sera actuellement actuellement. On logique, il faudra actuellement actuellement actuellement. Tu l'as cette vitesse, t'en sais que moi, je suis en vitesse en coquence. C'est a qu'on interpe., MAISDOUR M franais GENRE  NATTEIGNABLE franais ENTRE GUILLEMETS franais eDF PUISQUENENDEMF FINA4B franals ep G JAIDeJ franais TEAM franais PROPRE RECORD PERSONNED franals DUM franals  franals   franais franais POPCORN 13.15S franais   POINT franais D 1 franais eDF 128 franais co 1-06CM JE POPCORN  Sasha Zhoya La nouvelle pplte de l'athlt TeaN MMEHAUTEUR franais IEAM PoPCorn LE RECORD DU franais SURGTTBTAI4E 4A franais TEAM eDF 14e777 BS Hordl Eiics  HIko PIKO 78K 8G  HKO ZIKC 0 d51l OK TDK  franais  eDF 0 Zhoy FrANCE  22 GoKDelivels TDI IK live 0 TDK er DONC C'TAIT EUH POPCORN Sasha Zhoya La nouvelle pplte de lathltl Teak SEIKO SEIKO 5.3 SFt T82 Worlo Athletics Under 20 Championships  franais TEAM eDF SEIKO 3 ONPS 21 sa FAthLETIC CHAMPIC 7aizobi SEIKO SEIKC AIROBI CITY COUNTY SEIK SEIKO ADo FraNCE SEIKO Salcacom ZHOYA Zhoy AM eof C POPCORN  Sasha Zhoya La nouvelle pplte de l'athlt VITESSEEUHPUTAIN franals Sulonenw ZHOYA ZoYA FRANL FRANCE Soloncom ZHOYA NA ooe Znoya GETTE VITESSBEN franals D TAVAIS FAIT franais ATI WORLD TULYAS franais MAIS A VA POPCORN  Sasha Zhoya La nouvelle pplte de l'athlt 7 FranCE Taat  C FRANCE 'Salaricom WoAnr POURRAIS DASSER EN POPCORN  Sasha Zhoya La nouvelle pplte de l'athlt Tean 4A MME COURSB franals Ax ed TAILLE PZUS PETITE POPCORN Sasha Zhoya La nouvelle pplte de lathltl 1272 franals FrancC 21 FrancE 21 ZHOYA mova  franals Teak cV SERA HABITU MAINTENANT POPCORN Sasha Zhoya La nouvelle pplte de lathltl TAILLEDE99 franais eDf ET APReS TU franais 90121 prance Vaac ao FRANCE Her ENL POPCORN Sasha Zhoya La nouvelle pplte de lathltl HAESDE  franais eDF POPCORN franais GENRE A JOUE PCORN Sasha Zhoya La nouvelle pplte de lathltlsme fr V JAIFAIT franais TEAM HAIS franais eDF QUE JE VEUX Popcorn 13.15S franais 4 er 72 franais TEAK Sca DTAILS ET CETERA franals franais F A MEDIT franais TEAM HaIS  franais TEAM An MAIS P MOI POPCORN Sasha Zhoya La nouvelle pplte de lathlti cor 0 DES DTAIZS POPCORN Sasha Zhoya La nouvelle pplte de lathlti JUNI franais IEAM C  franais FAIT EN DESS franais P N franais eDF HUMAINS 1PEU MME SI G'eTAIT franais franais\n"
     ]
    }
   ],
   "source": [
    "download_tiktok_audio(video_url, output_filename)\n",
    "is_music = check_audio(audio_filename)\n",
    "video_audio = transcript_audio_to_text(audio_filename, is_music)\n",
    "get_tiktok_metadata(video_url, output_metadata_filename)\n",
    "video_title, video_description, video_time = extract_metadata(output_metadata_filename)\n",
    "print(f\"video time : {video_time} seconds\")\n",
    "download_video(video_url, output_metadata_filename, video_time)\n",
    "extract_video_frames(video_title, video_time)\n",
    "reader = create_reader()\n",
    "video_frame_text = extract_text_from_frames(reader, frame_folder=FRAME_FOLDER, video_time=video_time)\n",
    "input_text = generate_input_text(video_description, video_audio, video_frame_text)\n",
    "cleaned_text = clean_text(str(input_text))\n",
    "print(\"cleaned text : \" + cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With x talking records and logistics , En 2 000 finales de ces championnats du monde, tu te propres encore personnels sur cette taille l, 106 13 secondes 15 centimes Le record cest 128 quel point vois genre, inatniable entre guillemets, comment a Cest que pour nous, jallais dire les humains un peu normaux, veux genre justement des dtails, etc Comment Oui, Je a, a joue mais moi, dans ma tte, comme jai dj fait en dessous ce chrono, junior, avec mains plus basses Et le mme truc fait, soit son 12, me dit la hauteur 06, je pourrais passer 80, ma pas temps Estce coup, as 12 secondes, 72, on voyait A2, 99 Ouais, donc ctait petite, mais On sera actuellement actuellement logique, il faudra Tu las vitesse, ten sais suis vitesse coquence quon interpe, MAISDOUR M franais GENRE NATTEIGNABLE ENTRE GUILLEMETS eDF PUISQUENENDEMF FINA4B franals ep G JAIDeJ TEAM PROPRE RECORD PERSONNED DUM POPCORN 1315S POINT D 1 128 co 106CM JE Sasha Zhoya La nouvelle pplte lathlt TeaN MMEHAUTEUR IEAM PoPCorn LE DU SURGTTBTAI4E 4A 14e777 BS Hordl Eiics HIko PIKO 78K 8G HKO ZIKC 0 d51l OK TDK Zhoy FrANCE 22 GoKDelivels TDI IK live er DONC CTAIT EUH lathltl Teak SEIKO 53 SFt T82 Worlo Athletics Under 20 Championships 3 ONPS 21 sa FAthLETIC CHAMPIC 7aizobi SEIKC AIROBI CITY COUNTY SEIK ADo FraNCE Salcacom ZHOYA AM eof C VITESSEEUHPUTAIN Sulonenw ZoYA FRANL FRANCE Soloncom NA ooe Znoya GETTE VITESSBEN TAVAIS FAIT ATI WORLD TULYAS MAIS A VA 7 FranCE Taat Salaricom WoAnr POURRAIS DASSER EN Tean MME COURSB Ax ed TAILLE PZUS PETITE 1272 FrancC FrancE mova cV SERA HABITU MAINTENANT TAILLEDE99 eDf ET APReS TU 90121 prance Vaac ao Her ENL HAESDE JOUE PCORN lathltlsme fr V JAIFAIT HAIS QUE VEUX Popcorn 4 72 TEAK Sca DTAILS CETERA F MEDIT HaIS An P MOI lathlti cor DES DTAIZS JUNI DESS N HUMAINS 1PEU SI GeTAIT\n"
     ]
    }
   ],
   "source": [
    "new = remove_duplicates(cleaned_text)\n",
    "new = preprocess_text(new)\n",
    "\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With x talking records and logistics , En 2 000 finales de ces championnats du monde, tu te propres encore personnels sur cette taille l, 106 13 secondes 15 centimes Le record cest 128 quel point vois genre, inatniable entre guillemets, comment a Cest que pour nous, jallais dire les humains un peu normaux, veux genre justement des dtails, etc Comment Oui, Je a, a joue mais moi, dans ma tte, comme jai dj fait en dessous ce chrono, junior, avec mains plus basses Et le mme truc fait, soit son 12, me dit la hauteur 06, je pourrais passer 80, ma pas temps Estce coup, as 12 secondes, 72, on voyait A2, 99 Ouais, donc ctait petite, mais On sera actuellement actuellement logique, il faudra Tu las vitesse, ten sais suis vitesse coquence quon interpe, MAISDOUR M franais GENRE NATTEIGNABLE ENTRE GUILLEMETS eDF PUISQUENENDEMF FINA4B franals ep G JAIDeJ TEAM PROPRE RECORD PERSONNED DUM POPCORN 1315S POINT D 1 128 co 106CM JE Sasha Zhoya La nouvelle pplte lathlt TeaN MMEHAUTEUR IEAM PoPCorn LE DU SURGTTBTAI4E 4A 14e777 BS Hordl Eiics HIko PIKO 78K 8G HKO ZIKC 0 d51l OK TDK Zhoy FrANCE 22 GoKDelivels TDI IK live er DONC CTAIT EUH lathltl Teak SEIKO 53 SFt T82 Worlo Athletics Under 20 Championships 3 ONPS 21 sa FAthLETIC CHAMPIC 7aizobi SEIKC AIROBI CITY COUNTY SEIK ADo FraNCE Salcacom ZHOYA AM eof C VITESSEEUHPUTAIN Sulonenw ZoYA FRANL FRANCE Soloncom NA ooe Znoya GETTE VITESSBEN TAVAIS FAIT ATI WORLD TULYAS MAIS A VA 7 FranCE Taat Salaricom WoAnr POURRAIS DASSER EN Tean MME COURSB Ax ed TAILLE PZUS PETITE 1272 FrancC FrancE mova cV SERA HABITU MAINTENANT TAILLEDE99 eDf ET APReS TU 90121 prance Vaac ao Her ENL HAESDE JOUE PCORN lathltlsme fr V JAIFAIT HAIS QUE VEUX Popcorn 4 72 TEAK Sca DTAILS CETERA F MEDIT HaIS An P MOI lathlti cor DES DTAIZS JUNI DESS N HUMAINS 1PEU SI GeTAIT\n",
      "{\n",
      "\"place_number\" : \"1\",\n",
      "\"place_1\" : \"Paris\",\n",
      "\"city\" : \"Paris\",\n",
      "\"country\" : \"France\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_number</th>\n",
       "      <th>place_1</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Paris</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  place_number place_1   city country\n",
       "0            1   Paris  Paris  France"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(new)\n",
    "output = nlp_forecast(gpt_client, str(input_text))\n",
    "dico = eval(output)\n",
    "data = pd.DataFrame(dico, index=[0])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = int(data[\"place_number\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nairobi City County'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"place_1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_places = []\n",
    "for i in range(1, pn+1):\n",
    "    list_of_places.append(data[f\"place_{i}\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = (\n",
    "    supabase.table(\"generated_text\")\n",
    "    .insert({\n",
    "        \"video_url\": video_url,\n",
    "        \"video_description_text\" : video_description,\n",
    "        \"video_frame_text\" : video_frame_text ,\n",
    "        \"video_audio_text\" : video_audio,\n",
    "        \"video_cleaned_text\" : cleaned_text,\n",
    "        \"place_number\" : int(data[\"place_number\"][0]),\n",
    "        \"place_city\" : data[\"city\"][0],\n",
    "        \"place_country\" : data[\"country\"][0],\n",
    "        \"output\" : list_of_places\n",
    "        })\n",
    "    .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(FRAME_FOLDER)\n",
    "shutil.rmtree(RAW_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
