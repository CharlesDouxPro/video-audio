{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp as yt\n",
    "import whisper\n",
    "import pyktok as pyk\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import spacy\n",
    "import os\n",
    "import ffmpeg\n",
    "import easyocr\n",
    "import shutil\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from ShazamAPI import Shazam\n",
    "from langdetect import detect, DetectorFactory\n",
    "import re\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"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\"\n",
    "gpt_client = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client\n",
    "\n",
    "url: str = \"https://pqhcubzkrlbvljbvsmem.supabase.co\"\n",
    "key: str = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InBxaGN1YnprcmxidmxqYnZzbWVtIiwicm9sZSI6ImFub24iLCJpYXQiOjE3Mjc4NzgyNDYsImV4cCI6MjA0MzQ1NDI0Nn0.5Yt2zMMm09II29COY58lXIvIQID1N7FM6JL3-B9jhdU\"\n",
    "supabase: Client = create_client(url, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client(\"s3\")\n",
    "\n",
    "DB_CONNECTION = \"postgresql://postgres.pqhcubzkrlbvljbvsmem:baw1mART4@aws-0-eu-west-3.pooler.supabase.com:5432/postgres\"\n",
    "DB_PASSWORD = \"baw1mART4-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_FOLDER = \"FRAMES\"\n",
    "RAW_DATA_FOLDER = \"DATA\"\n",
    "\n",
    "os.mkdir(FRAME_FOLDER)\n",
    "os.mkdir(RAW_DATA_FOLDER)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url = \"https://www.tiktok.com/@sashazhoyaofficial/video/7372174468665347361?is_from_webapp=1&sender_device=pc&web_id=7423833413503174176\"  \n",
    "output_filename = f\"{RAW_DATA_FOLDER}/audio\"\n",
    "audio_filename = f\"{RAW_DATA_FOLDER}/audio.mp3\"\n",
    "output_metadata_filename=f\"{RAW_DATA_FOLDER}/video_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tiktok_audio(video_url, output_filename):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',\n",
    "        'outtmpl': output_filename,\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "    }\n",
    "\n",
    "    with yt.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([video_url])\n",
    "\n",
    "def transcript_audio_to_text(audio_filename, is_music):\n",
    "    if is_music is False : \n",
    "        model = whisper.load_model(\"base\")\n",
    "        result = model.transcribe(audio_filename)\n",
    "        text = result[\"text\"]\n",
    "        print(f\"text : {result[\"text\"]}\")\n",
    "\n",
    "\n",
    "        return text\n",
    "    else:\n",
    "        return \"\", \" \"\n",
    "\n",
    "\n",
    "def get_tiktok_metadata(video_url, output_metadata_filename):\n",
    "    pyk.save_tiktok(video_url,\n",
    "                False,\n",
    "                output_metadata_filename)\n",
    "    \n",
    "\n",
    "def extract_metadata(output_metadata_filename):\n",
    "    data = pd.read_csv(output_metadata_filename)\n",
    "    video_author = data[\"author_username\"][0]\n",
    "    video_id = data[\"video_id\"][0]\n",
    "    video_time = data[\"video_duration\"][0]\n",
    "    video_title = f\"@{video_author}_video_{video_id}.mp4\"\n",
    "    video_description = data[\"video_description\"][0]\n",
    "    return video_title, video_description, video_time\n",
    "\n",
    "\n",
    "def download_video(video_url, output_metadata_filename, video_time):\n",
    "    if video_time <= 150:\n",
    "        pyk.save_tiktok(video_url,\n",
    "                True,\n",
    "                output_metadata_filename)\n",
    "\n",
    "\n",
    "def extract_video_frames(video_title , video_time, fps = 1):\n",
    "    if video_time > 150:\n",
    "        print(\"Video too long, no video extraction\")\n",
    "        return \n",
    "    else:\n",
    "        output_frames = f'{FRAME_FOLDER}/frame_%04d.png'\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(video_title)\n",
    "            .output(output_frames, vf=f'fps={fps}')\n",
    "            .run()\n",
    "        )\n",
    "\n",
    "        print(\"Frames extraction done.\")\n",
    "\n",
    "\n",
    "def create_reader():\n",
    "    reader = easyocr.Reader(['en','fr','es','it','de'])\n",
    "    return reader\n",
    "\n",
    "\n",
    "def extract_text_from_frames(reader, frame_folder, video_time):\n",
    "    if video_time > 150 : \n",
    "        print(\"no frame extraction\")\n",
    "        return \" \"\n",
    "    else:\n",
    "        video_frame_text = []\n",
    "        for frame in os.listdir(frame_folder):\n",
    "            result = reader.readtext(f\"{frame_folder}/{frame}\")\n",
    "            for detection in result:\n",
    "                video_frame_text.append(detection[1])\n",
    "        print( video_frame_text)\n",
    "        return video_frame_text\n",
    "\n",
    "\n",
    "def generate_input_text(video_description, video_audio, video_frame_text):\n",
    "    generated_texts = video_description , video_audio ,  \" \".join(video_frame_text)\n",
    "    print( generated_texts)\n",
    "    return generated_texts\n",
    "\n",
    "\n",
    "def forecast_places(input_generated_texts):\n",
    "    nlp = spacy.load(\"xx_ent_wiki_sm\")\n",
    "    doc = nlp(str(input_generated_texts))\n",
    "    forecasted_places = [ent.text for ent in doc.ents if ent.label_  in [\"LOC\"]]\n",
    "    print(\"forecasted places :\", forecasted_places)\n",
    "    return forecasted_places\n",
    "\n",
    "\n",
    "def check_audio(audio_file_name): \n",
    "    try:\n",
    "        with open(audio_file_name, 'rb') as audio_file:\n",
    "            mp3_file_content_to_recognize = audio_file.read()\n",
    "        \n",
    "            shazam = Shazam(mp3_file_content_to_recognize)\n",
    "            recognize_generator = shazam.recognizeSong()\n",
    "            if True:\n",
    "                print(\"Identified music.\")\n",
    "                return False\n",
    "    except FileNotFoundError:\n",
    "        print(\"No music\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error append: {e}\")\n",
    "    return False\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    text = re.sub(r'[@#]\\w+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s,.\\'‚Äô-]', '', text) \n",
    "    return text\n",
    "\n",
    "\n",
    "def nlp_forecast(client, text): \n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"You are usefull to seek places in a text with their city and country\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "            \"\"\"\n",
    "            Instructions:\n",
    "                - Given the text at the end, find all the places to visit quote in this text. \n",
    "                - Return the number of places you find\n",
    "                - Return the city of these places in English\n",
    "                - Return the country of these places in English\n",
    "                - Do not return the same place multiple time\n",
    "                - Return only in the python dictionary format like below\n",
    "                - Do not include any additional formatting, such as markdown code blocks\n",
    "\n",
    "\n",
    "            {\n",
    "            \"place_number\" : \"<number of places>\",\n",
    "            \"place_1\" : \"<first place you find in the text>\",\n",
    "            \"place_2\" : \"<second place you find in the text>\", \n",
    "            ...,\n",
    "            \"place_n\" : \"<the nth place you find in the text>\n",
    "            \"city\" :\" <the city of these places>\", \n",
    "            \"country\" : \"<the country of these places>\"\n",
    "             },\n",
    "\n",
    "             \n",
    "            The text could be bad formated but just focus to find similitude with the places you know \n",
    "            There is the text to analyse :\n",
    "            \"\"\" + text\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "    output = completion.choices[0].message.content\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    words = text.split()\n",
    "    seen = set()\n",
    "    unique_words = []\n",
    "    for word in words:\n",
    "        if word not in seen:\n",
    "            unique_words.append(word)\n",
    "            seen.add(word)\n",
    "    \n",
    "    return ' '.join(unique_words)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = re.sub(r\"[^\\w\\s,]\", \"\", text)\n",
    "    cleaned_text = re.sub(r\",+\", \",\", cleaned_text)\n",
    "    cleaned_text = cleaned_text.replace(\",,\", \",\")  \n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TikTok] Extracting URL: https://www.tiktok.com/@sashazhoyaofficial/video/7372174468665347361?is_from_webapp=1&sender_devi...=7423833413503174176\n",
      "[TikTok] 7372174468665347361: Downloading webpage\n",
      "[info] 7372174468665347361: Downloading 1 format(s): bytevc1_1080p_720687-1\n",
      "[download] Destination: DATA/audio\n",
      "[download] 100% of    7.31MiB in 00:00:00 at 7.61MiB/s     \n",
      "[ExtractAudio] Destination: DATA/audio.mp3\n",
      "Deleting original file DATA/audio (pass -k to keep)\n",
      "Identified music.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/miniconda3/envs/testing/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/Users/user/miniconda3/envs/testing/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text :  En 2 000 finales de ces championnats du monde, tu te propres encore personnels sur cette taille l√†, 1-0-6. 13 secondes 15 centi√®mes. Le record du monde, c'est √† 12.8 √† quel point tu vois genre, c'est inat√©niable entre guillemets, √† quel point comment tu vois √ßa. C'est que pour nous, j'allais dire les humains un peu normaux, tu veux dire genre... C'est justement un des d√©tails, etc. Comment ? Oui, comment ? Je vois √ßa, √ßa joue √† des d√©tails, mais pour moi, dans ma t√™te, comme j'ai d√©j√† fait en dessous ce chrono, mais c'est dans un taille junior, avec les mains plus basses. Et le m√™me truc que tu vois j'ai fait, soit son 12, √ßa me dit que sur la m√™me hauteur √† 0-6, je pourrais passer en dessous les 80, mais √ßa m'a pas du temps. Est-ce que du coup, tu as fait 12 secondes, de 72, on voyait le record sur des A2, quel taille ? 99 centi√®mes. Ouais, donc c'√©tait un taille plus petite, mais... On sera actuellement actuellement. On logique, il faudra actuellement actuellement actuellement. Tu l'as cette vitesse, t'en sais que moi, je suis en vitesse en √©coquence. C'est √ßa qu'on interpe.\n",
      "Saved metadata for video\n",
      " https://www.tiktok.com/@sashazhoyaofficial/video/7372174468665347361?is_from_webapp=1&sender_device=pc&web_id=7423833413503174176 \n",
      "to\n",
      " /Users/user/Documents/ProjetIATiktok\n",
      "video time : 85 seconds\n",
      "Saved video\n",
      " https://www.tiktok.com/@sashazhoyaofficial/video/7372174468665347361?is_from_webapp=1&sender_device=pc&web_id=7423833413503174176 \n",
      "to\n",
      " /Users/user/Documents/ProjetIATiktok\n",
      "Saved metadata for video\n",
      " https://www.tiktok.com/@sashazhoyaofficial/video/7372174468665347361?is_from_webapp=1&sender_device=pc&web_id=7423833413503174176 \n",
      "to\n",
      " /Users/user/Documents/ProjetIATiktok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.2 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with Apple clang version 15.0.0 (clang-1500.3.9.4)\n",
      "  configuration: --prefix=/opt/homebrew/Cellar/ffmpeg/7.0.2_1 --enable-shared --enable-pthreads --enable-version3 --cc=clang --host-cflags= --host-ldflags='-Wl,-ld_classic' --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libaribb24 --enable-libbluray --enable-libdav1d --enable-libharfbuzz --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librist --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox --enable-audiotoolbox --enable-neon\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '@sashazhoyaofficial_video_7372174468665347361.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    comment         : vid:v0f044gc0000cp7iugvog65lda6kkpl0\n",
      "    aigc_info       : {\"aigc_label_type\": 0}\n",
      "    vid_md5         : 94203df8cd159f58fe322e85a26bdfb8\n",
      "    encoder         : Lavf58.76.100\n",
      "  Duration: 00:01:25.13, start: 0.000000, bitrate: 1026 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 576x1024 [SAR 1:1 DAR 9:16], 988 kb/s, 29.21 fps, 30 tbr, 15360 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](und): Audio: aac (HE-AACv2) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 32 kb/s (default)\n",
      "      Metadata:\n",
      "        handler_name    : SoundHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128400000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128410000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128420000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128430000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128440000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128450000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128460000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128470000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "[swscaler @ 0x138c90000] [swscaler @ 0x128480000] No accelerated colorspace conversion found from yuv420p to rgb24.\n",
      "Output #0, image2, to 'FRAMES/frame_%04d.png':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    comment         : vid:v0f044gc0000cp7iugvog65lda6kkpl0\n",
      "    aigc_info       : {\"aigc_label_type\": 0}\n",
      "    vid_md5         : 94203df8cd159f58fe322e85a26bdfb8\n",
      "    encoder         : Lavf61.1.100\n",
      "  Stream #0:0(und): Video: png, rgb24(pc, gbr/bt709/bt709, progressive), 576x1024 [SAR 1:1 DAR 9:16], q=2-31, 200 kb/s, 1 fps, 1 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.3.100 png\n",
      "[out#0/image2 @ 0x148021590] video:43880KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: unknown\n",
      "frame=   85 fps= 72 q=-0.0 Lsize=N/A time=00:01:25.00 bitrate=N/A speed=71.9x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames extraction done.\n",
      "['MAISDOUR M@I', 'fran√ßais', 'GENRE @EST', '[NATTEIGNABLE', 'fran√ßais', 'ENTRE GUILLEMETS', 'fran√ßais', 'eDF', 'PUISQUENENDEMF', 'FINA4B', 'fran√ßals', 'ep', 'G@MME JAIDeJ√†', 'fran√ßais', 'TEAM', 'fran√ßais', 'PROPRE RECORD', 'PERSONNED', 'fran√ßals', 'DUM@NDE', 'fran√ßals', '@OMMENT', 'fran√ßals', '√† @UELPOINT', 'fran√ßais', 'fran√ßais', 'POPCORN', '13.15S', 'fran√ßais', '√† @UEL POINT', 'fran√ßais', 'D@NG 1@6GM', 'fran√ßais', 'eDF', '128', 'fran√ßais', 'co', '1-06CM JE', 'POPCORN ', 'Sasha Zhoya', \"La nouvelle p√©plte de l'athl√©t\", 'TeaN', 'M√™MEHAUTEUR', 'fran√ßais', 'IEAM', 'PoPCorn', 'LE RECORD DU', 'fran√ßais', 'SURGTTBTAI4E', '4A', 'fran√ßais', 'TEAM', 'eDF', '14e777', 'BS', 'Hordl', 'Eiics', '#TDI', 'HIko', 'PIKO', '78K', '8G', '#TDK', 'HKO', 'ZIKC', '0', 'd51l', 'OK', 'TDK', '@UAIS', 'fran√ßais', '@KAM', 'eDF', '0', 'Zhoy', 'FrANCE _', '22', 'GoKDelivels', 'TDI', 'IK', 'live', '0=', 'TDK', 'er', \"DONC C'√©TAIT EUH\", 'POPCORN', 'Sasha Zhoya', 'La nouvelle p√©plte de lathl√©tl', 'Teak', 'SEIKO', 'SEIKO', '5.3', 'SFt', 'T82', 'Worlo Athletics Under 20 Championships', '{', 'fran√ßais', 'TEAM', 'eDF', 'SEIKO', '3', 'ONPS', '21', 'sa', 'FAthLETIC', 'CHAMPIC', '7aizobi', 'SEIKO', 'SEIKC', 'AIROBI CITY COUNTY', 'SEIK', 'SEIKO', 'ADo', 'FraNCE', 'SEIKO', 'Salcacom', 'ZHOYA', 'Zhoy', 'AM', 'eof', 'C@UP', 'POPCORN ', 'Sasha Zhoya', \"La nouvelle p√©plte de l'athl√©t\", 'VITESSEEUHPUTAIN', 'fran√ßals', 'Sulonenw', 'ZHOYA', 'ZoYA', 'FRANL', 'FRANCE', 'Soloncom', 'ZHOYA', 'NA ooe', 'Znoya', 'GETTE VITESSBEN', 'fran√ßals', 'D@NC TAVAIS FAIT', 'fran√ßais', 'ATI', 'WORLD', 'TULYAS@ETTB', 'fran√ßais', 'MAIS √ßA VA', 'POPCORN ', 'Sasha Zhoya', \"La nouvelle p√©plte de l'athl√©t\", '7', 'FranCE', 'Taat', '‚Ç¨', 'C', 'FRANCE', \"'Salaricom\", 'WoAnr', 'POURRAIS DASSER', 'EN', 'POPCORN ', 'Sasha Zhoya', \"La nouvelle p√©plte de l'athl√©t\", 'Tean', '4A M√™ME COURSB', 'fran√ßals', 'Ax', 'ed', 'TAILLE PZUS PETITE', 'POPCORN', 'Sasha Zhoya', 'La nouvelle p√©plte de lathl√©tl', '1272', 'fran√ßals', 'FrancC', '21', 'FrancE', '21', 'ZHOYA', 'mova', '@ELERECORD', 'fran√ßals', 'Teak', 'cV', 'SERA HABITU√©', 'MAINTENANT', 'POPCORN', 'Sasha Zhoya', 'La nouvelle p√©plte de lathl√©tl', 'TAILLEDE99', 'fran√ßais', 'eDf', 'ET APReS TU', 'fran√ßais', '90121', 'prance', 'Vaac', 'ao', 'FRANCE', 'Her', 'ENL@GIQUE', 'POPCORN', 'Sasha Zhoya', 'La nouvelle p√©plte de lathl√©tl', 'HAESDE @0EL4E', 'fran√ßais', 'eDF', 'POPCORN', 'fran√ßais', 'GENRE √ßA JOUE', 'PCORN', 'Sasha Zhoya', 'La nouvelle p√©plte de lathl√©tlsme fr', 'V@iS JAIFAIT', 'fran√ßais', 'TEAM', 'HAIS@T@@', 'fran√ßais', '<eDF', 'QUE JE VEUX', 'Popcorn', '13.15S', 'fran√ßais', '4 er', '72', 'fran√ßais', 'TEAK', 'Sca', 'D√©TAILS ET CETERA', 'fran√ßals', 'fran√ßais', 'F', '√ßA MEDIT', 'fran√ßais', 'TEAM', 'HaIS @72E', 'fran√ßais', 'TEAM', 'An', 'MAIS P@UR MOI', 'POPCORN', 'Sasha Zhoya', 'La nouvelle p√©plte de lathl√©ti', 'cor', '0', 'DES D√©TAIZS', 'POPCORN', 'Sasha Zhoya', 'La nouvelle p√©plte de lathl√©ti', 'JUNI@RDF', 'fran√ßais', 'IEAM', 'C@MMENTEUH', '@UAIS', 'fran√ßais', 'FAIT EN DESS@US', 'fran√ßais', 'P@UR N@US', 'fran√ßais', '&eDF', 'HUMAINS 1PEU', \"M√™ME SI G'eTAIT\", 'fran√ßais', 'fran√ßais']\n",
      "('With @Domingo x @EDF talking records and logistics üßê #roadtoparis #ChampionsTalk #sportstiktok #proathlete #podcast ', \" En 2 000 finales de ces championnats du monde, tu te propres encore personnels sur cette taille l√†, 1-0-6. 13 secondes 15 centi√®mes. Le record du monde, c'est √† 12.8 √† quel point tu vois genre, c'est inat√©niable entre guillemets, √† quel point comment tu vois √ßa. C'est que pour nous, j'allais dire les humains un peu normaux, tu veux dire genre... C'est justement un des d√©tails, etc. Comment ? Oui, comment ? Je vois √ßa, √ßa joue √† des d√©tails, mais pour moi, dans ma t√™te, comme j'ai d√©j√† fait en dessous ce chrono, mais c'est dans un taille junior, avec les mains plus basses. Et le m√™me truc que tu vois j'ai fait, soit son 12, √ßa me dit que sur la m√™me hauteur √† 0-6, je pourrais passer en dessous les 80, mais √ßa m'a pas du temps. Est-ce que du coup, tu as fait 12 secondes, de 72, on voyait le record sur des A2, quel taille ? 99 centi√®mes. Ouais, donc c'√©tait un taille plus petite, mais... On sera actuellement actuellement. On logique, il faudra actuellement actuellement actuellement. Tu l'as cette vitesse, t'en sais que moi, je suis en vitesse en √©coquence. C'est √ßa qu'on interpe.\", \"MAISDOUR M@I fran√ßais GENRE @EST [NATTEIGNABLE fran√ßais ENTRE GUILLEMETS fran√ßais eDF PUISQUENENDEMF FINA4B fran√ßals ep G@MME JAIDeJ√† fran√ßais TEAM fran√ßais PROPRE RECORD PERSONNED fran√ßals DUM@NDE fran√ßals @OMMENT fran√ßals √† @UELPOINT fran√ßais fran√ßais POPCORN 13.15S fran√ßais √† @UEL POINT fran√ßais D@NG 1@6GM fran√ßais eDF 128 fran√ßais co 1-06CM JE POPCORN  Sasha Zhoya La nouvelle p√©plte de l'athl√©t TeaN M√™MEHAUTEUR fran√ßais IEAM PoPCorn LE RECORD DU fran√ßais SURGTTBTAI4E 4A fran√ßais TEAM eDF 14e777 BS Hordl Eiics #TDI HIko PIKO 78K 8G #TDK HKO ZIKC 0 d51l OK TDK @UAIS fran√ßais @KAM eDF 0 Zhoy FrANCE _ 22 GoKDelivels TDI IK live 0= TDK er DONC C'√©TAIT EUH POPCORN Sasha Zhoya La nouvelle p√©plte de lathl√©tl Teak SEIKO SEIKO 5.3 SFt T82 Worlo Athletics Under 20 Championships { fran√ßais TEAM eDF SEIKO 3 ONPS 21 sa FAthLETIC CHAMPIC 7aizobi SEIKO SEIKC AIROBI CITY COUNTY SEIK SEIKO ADo FraNCE SEIKO Salcacom ZHOYA Zhoy AM eof C@UP POPCORN  Sasha Zhoya La nouvelle p√©plte de l'athl√©t VITESSEEUHPUTAIN fran√ßals Sulonenw ZHOYA ZoYA FRANL FRANCE Soloncom ZHOYA NA ooe Znoya GETTE VITESSBEN fran√ßals D@NC TAVAIS FAIT fran√ßais ATI WORLD TULYAS@ETTB fran√ßais MAIS √ßA VA POPCORN  Sasha Zhoya La nouvelle p√©plte de l'athl√©t 7 FranCE Taat ‚Ç¨ C FRANCE 'Salaricom WoAnr POURRAIS DASSER EN POPCORN  Sasha Zhoya La nouvelle p√©plte de l'athl√©t Tean 4A M√™ME COURSB fran√ßals Ax ed TAILLE PZUS PETITE POPCORN Sasha Zhoya La nouvelle p√©plte de lathl√©tl 1272 fran√ßals FrancC 21 FrancE 21 ZHOYA mova @ELERECORD fran√ßals Teak cV SERA HABITU√© MAINTENANT POPCORN Sasha Zhoya La nouvelle p√©plte de lathl√©tl TAILLEDE99 fran√ßais eDf ET APReS TU fran√ßais 90121 prance Vaac ao FRANCE Her ENL@GIQUE POPCORN Sasha Zhoya La nouvelle p√©plte de lathl√©tl HAESDE @0EL4E fran√ßais eDF POPCORN fran√ßais GENRE √ßA JOUE PCORN Sasha Zhoya La nouvelle p√©plte de lathl√©tlsme fr V@iS JAIFAIT fran√ßais TEAM HAIS@T@@ fran√ßais <eDF QUE JE VEUX Popcorn 13.15S fran√ßais 4 er 72 fran√ßais TEAK Sca D√©TAILS ET CETERA fran√ßals fran√ßais F √ßA MEDIT fran√ßais TEAM HaIS @72E fran√ßais TEAM An MAIS P@UR MOI POPCORN Sasha Zhoya La nouvelle p√©plte de lathl√©ti cor 0 DES D√©TAIZS POPCORN Sasha Zhoya La nouvelle p√©plte de lathl√©ti JUNI@RDF fran√ßais IEAM C@MMENTEUH @UAIS fran√ßais FAIT EN DESS@US fran√ßais P@UR N@US fran√ßais &eDF HUMAINS 1PEU M√™ME SI G'eTAIT fran√ßais fran√ßais\")\n",
      "cleaned text : 'With  x  talking records and logistics       ',  En 2 000 finales de ces championnats du monde, tu te propres encore personnels sur cette taille l, 1-0-6. 13 secondes 15 centimes. Le record du monde, c'est  12.8  quel point tu vois genre, c'est inatniable entre guillemets,  quel point comment tu vois a. C'est que pour nous, j'allais dire les humains un peu normaux, tu veux dire genre... C'est justement un des dtails, etc. Comment  Oui, comment  Je vois a, a joue  des dtails, mais pour moi, dans ma tte, comme j'ai dj fait en dessous ce chrono, mais c'est dans un taille junior, avec les mains plus basses. Et le mme truc que tu vois j'ai fait, soit son 12, a me dit que sur la mme hauteur  0-6, je pourrais passer en dessous les 80, mais a m'a pas du temps. Est-ce que du coup, tu as fait 12 secondes, de 72, on voyait le record sur des A2, quel taille  99 centimes. Ouais, donc c'tait un taille plus petite, mais... On sera actuellement actuellement. On logique, il faudra actuellement actuellement actuellement. Tu l'as cette vitesse, t'en sais que moi, je suis en vitesse en coquence. C'est a qu'on interpe., MAISDOUR M franais GENRE  NATTEIGNABLE franais ENTRE GUILLEMETS franais eDF PUISQUENENDEMF FINA4B franals ep G JAIDeJ franais TEAM franais PROPRE RECORD PERSONNED franals DUM franals  franals   franais franais POPCORN 13.15S franais   POINT franais D 1 franais eDF 128 franais co 1-06CM JE POPCORN  Sasha Zhoya La nouvelle pplte de l'athlt TeaN MMEHAUTEUR franais IEAM PoPCorn LE RECORD DU franais SURGTTBTAI4E 4A franais TEAM eDF 14e777 BS Hordl Eiics  HIko PIKO 78K 8G  HKO ZIKC 0 d51l OK TDK  franais  eDF 0 Zhoy FrANCE  22 GoKDelivels TDI IK live 0 TDK er DONC C'TAIT EUH POPCORN Sasha Zhoya La nouvelle pplte de lathltl Teak SEIKO SEIKO 5.3 SFt T82 Worlo Athletics Under 20 Championships  franais TEAM eDF SEIKO 3 ONPS 21 sa FAthLETIC CHAMPIC 7aizobi SEIKO SEIKC AIROBI CITY COUNTY SEIK SEIKO ADo FraNCE SEIKO Salcacom ZHOYA Zhoy AM eof C POPCORN  Sasha Zhoya La nouvelle pplte de l'athlt VITESSEEUHPUTAIN franals Sulonenw ZHOYA ZoYA FRANL FRANCE Soloncom ZHOYA NA ooe Znoya GETTE VITESSBEN franals D TAVAIS FAIT franais ATI WORLD TULYAS franais MAIS A VA POPCORN  Sasha Zhoya La nouvelle pplte de l'athlt 7 FranCE Taat  C FRANCE 'Salaricom WoAnr POURRAIS DASSER EN POPCORN  Sasha Zhoya La nouvelle pplte de l'athlt Tean 4A MME COURSB franals Ax ed TAILLE PZUS PETITE POPCORN Sasha Zhoya La nouvelle pplte de lathltl 1272 franals FrancC 21 FrancE 21 ZHOYA mova  franals Teak cV SERA HABITU MAINTENANT POPCORN Sasha Zhoya La nouvelle pplte de lathltl TAILLEDE99 franais eDf ET APReS TU franais 90121 prance Vaac ao FRANCE Her ENL POPCORN Sasha Zhoya La nouvelle pplte de lathltl HAESDE  franais eDF POPCORN franais GENRE A JOUE PCORN Sasha Zhoya La nouvelle pplte de lathltlsme fr V JAIFAIT franais TEAM HAIS franais eDF QUE JE VEUX Popcorn 13.15S franais 4 er 72 franais TEAK Sca DTAILS ET CETERA franals franais F A MEDIT franais TEAM HaIS  franais TEAM An MAIS P MOI POPCORN Sasha Zhoya La nouvelle pplte de lathlti cor 0 DES DTAIZS POPCORN Sasha Zhoya La nouvelle pplte de lathlti JUNI franais IEAM C  franais FAIT EN DESS franais P N franais eDF HUMAINS 1PEU MME SI G'eTAIT franais franais\n"
     ]
    }
   ],
   "source": [
    "download_tiktok_audio(video_url, output_filename)\n",
    "is_music = check_audio(audio_filename)\n",
    "video_audio = transcript_audio_to_text(audio_filename, is_music)\n",
    "get_tiktok_metadata(video_url, output_metadata_filename)\n",
    "video_title, video_description, video_time = extract_metadata(output_metadata_filename)\n",
    "print(f\"video time : {video_time} seconds\")\n",
    "download_video(video_url, output_metadata_filename, video_time)\n",
    "extract_video_frames(video_title, video_time)\n",
    "reader = create_reader()\n",
    "video_frame_text = extract_text_from_frames(reader, frame_folder=FRAME_FOLDER, video_time=video_time)\n",
    "input_text = generate_input_text(video_description, video_audio, video_frame_text)\n",
    "cleaned_text = clean_text(str(input_text))\n",
    "print(\"cleaned text : \" + cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With x talking records and logistics , En 2 000 finales de ces championnats du monde, tu te propres encore personnels sur cette taille l, 106 13 secondes 15 centimes Le record cest 128 quel point vois genre, inatniable entre guillemets, comment a Cest que pour nous, jallais dire les humains un peu normaux, veux genre justement des dtails, etc Comment Oui, Je a, a joue mais moi, dans ma tte, comme jai dj fait en dessous ce chrono, junior, avec mains plus basses Et le mme truc fait, soit son 12, me dit la hauteur 06, je pourrais passer 80, ma pas temps Estce coup, as 12 secondes, 72, on voyait A2, 99 Ouais, donc ctait petite, mais On sera actuellement actuellement logique, il faudra Tu las vitesse, ten sais suis vitesse coquence quon interpe, MAISDOUR M franais GENRE NATTEIGNABLE ENTRE GUILLEMETS eDF PUISQUENENDEMF FINA4B franals ep G JAIDeJ TEAM PROPRE RECORD PERSONNED DUM POPCORN 1315S POINT D 1 128 co 106CM JE Sasha Zhoya La nouvelle pplte lathlt TeaN MMEHAUTEUR IEAM PoPCorn LE DU SURGTTBTAI4E 4A 14e777 BS Hordl Eiics HIko PIKO 78K 8G HKO ZIKC 0 d51l OK TDK Zhoy FrANCE 22 GoKDelivels TDI IK live er DONC CTAIT EUH lathltl Teak SEIKO 53 SFt T82 Worlo Athletics Under 20 Championships 3 ONPS 21 sa FAthLETIC CHAMPIC 7aizobi SEIKC AIROBI CITY COUNTY SEIK ADo FraNCE Salcacom ZHOYA AM eof C VITESSEEUHPUTAIN Sulonenw ZoYA FRANL FRANCE Soloncom NA ooe Znoya GETTE VITESSBEN TAVAIS FAIT ATI WORLD TULYAS MAIS A VA 7 FranCE Taat Salaricom WoAnr POURRAIS DASSER EN Tean MME COURSB Ax ed TAILLE PZUS PETITE 1272 FrancC FrancE mova cV SERA HABITU MAINTENANT TAILLEDE99 eDf ET APReS TU 90121 prance Vaac ao Her ENL HAESDE JOUE PCORN lathltlsme fr V JAIFAIT HAIS QUE VEUX Popcorn 4 72 TEAK Sca DTAILS CETERA F MEDIT HaIS An P MOI lathlti cor DES DTAIZS JUNI DESS N HUMAINS 1PEU SI GeTAIT\n"
     ]
    }
   ],
   "source": [
    "new = remove_duplicates(cleaned_text)\n",
    "new = preprocess_text(new)\n",
    "\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With x talking records and logistics , En 2 000 finales de ces championnats du monde, tu te propres encore personnels sur cette taille l, 106 13 secondes 15 centimes Le record cest 128 quel point vois genre, inatniable entre guillemets, comment a Cest que pour nous, jallais dire les humains un peu normaux, veux genre justement des dtails, etc Comment Oui, Je a, a joue mais moi, dans ma tte, comme jai dj fait en dessous ce chrono, junior, avec mains plus basses Et le mme truc fait, soit son 12, me dit la hauteur 06, je pourrais passer 80, ma pas temps Estce coup, as 12 secondes, 72, on voyait A2, 99 Ouais, donc ctait petite, mais On sera actuellement actuellement logique, il faudra Tu las vitesse, ten sais suis vitesse coquence quon interpe, MAISDOUR M franais GENRE NATTEIGNABLE ENTRE GUILLEMETS eDF PUISQUENENDEMF FINA4B franals ep G JAIDeJ TEAM PROPRE RECORD PERSONNED DUM POPCORN 1315S POINT D 1 128 co 106CM JE Sasha Zhoya La nouvelle pplte lathlt TeaN MMEHAUTEUR IEAM PoPCorn LE DU SURGTTBTAI4E 4A 14e777 BS Hordl Eiics HIko PIKO 78K 8G HKO ZIKC 0 d51l OK TDK Zhoy FrANCE 22 GoKDelivels TDI IK live er DONC CTAIT EUH lathltl Teak SEIKO 53 SFt T82 Worlo Athletics Under 20 Championships 3 ONPS 21 sa FAthLETIC CHAMPIC 7aizobi SEIKC AIROBI CITY COUNTY SEIK ADo FraNCE Salcacom ZHOYA AM eof C VITESSEEUHPUTAIN Sulonenw ZoYA FRANL FRANCE Soloncom NA ooe Znoya GETTE VITESSBEN TAVAIS FAIT ATI WORLD TULYAS MAIS A VA 7 FranCE Taat Salaricom WoAnr POURRAIS DASSER EN Tean MME COURSB Ax ed TAILLE PZUS PETITE 1272 FrancC FrancE mova cV SERA HABITU MAINTENANT TAILLEDE99 eDf ET APReS TU 90121 prance Vaac ao Her ENL HAESDE JOUE PCORN lathltlsme fr V JAIFAIT HAIS QUE VEUX Popcorn 4 72 TEAK Sca DTAILS CETERA F MEDIT HaIS An P MOI lathlti cor DES DTAIZS JUNI DESS N HUMAINS 1PEU SI GeTAIT\n",
      "{\n",
      "\"place_number\" : \"1\",\n",
      "\"place_1\" : \"Paris\",\n",
      "\"city\" : \"Paris\",\n",
      "\"country\" : \"France\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_number</th>\n",
       "      <th>place_1</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Paris</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  place_number place_1   city country\n",
       "0            1   Paris  Paris  France"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(new)\n",
    "output = nlp_forecast(gpt_client, str(input_text))\n",
    "dico = eval(output)\n",
    "data = pd.DataFrame(dico, index=[0])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = int(data[\"place_number\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nairobi City County'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"place_1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_places = []\n",
    "for i in range(1, pn+1):\n",
    "    list_of_places.append(data[f\"place_{i}\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = (\n",
    "    supabase.table(\"generated_text\")\n",
    "    .insert({\n",
    "        \"video_url\": video_url,\n",
    "        \"video_description_text\" : video_description,\n",
    "        \"video_frame_text\" : video_frame_text ,\n",
    "        \"video_audio_text\" : video_audio,\n",
    "        \"video_cleaned_text\" : cleaned_text,\n",
    "        \"place_number\" : int(data[\"place_number\"][0]),\n",
    "        \"place_city\" : data[\"city\"][0],\n",
    "        \"place_country\" : data[\"country\"][0],\n",
    "        \"output\" : list_of_places\n",
    "        })\n",
    "    .execute()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(FRAME_FOLDER)\n",
    "shutil.rmtree(RAW_DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
