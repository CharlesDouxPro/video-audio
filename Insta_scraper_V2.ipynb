{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "729a2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import config\n",
    "import json\n",
    "import os\n",
    "from urllib.parse import urlparse\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "833b157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the path to chromedriver.exe (download and save on your computer)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "#open the webpage\n",
    "driver.get(\"https://www.instagram.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbe88437",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'config' has no attribute 'username'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#enter username and password\u001b[39;00m\n\u001b[1;32m      6\u001b[0m username\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m----> 7\u001b[0m username\u001b[38;5;241m.\u001b[39msend_keys(\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43musername\u001b[49m)\n\u001b[1;32m      8\u001b[0m password\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m      9\u001b[0m password\u001b[38;5;241m.\u001b[39msend_keys(config\u001b[38;5;241m.\u001b[39mpassword)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'config' has no attribute 'username'"
     ]
    }
   ],
   "source": [
    "#target username\n",
    "username = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='username']\")))\n",
    "password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='password']\")))\n",
    "\n",
    "#enter username and password\n",
    "username.clear()\n",
    "username.send_keys(config.username)\n",
    "password.clear()\n",
    "password.send_keys(config.password)\n",
    "\n",
    "#target the login button and click it\n",
    "button = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\"))).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4813345",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\n0   chromedriver                        0x0000000100aa4200 cxxbridge1$str$ptr + 1907280\n1   chromedriver                        0x0000000100a9c6e8 cxxbridge1$str$ptr + 1875768\n2   chromedriver                        0x00000001006b0260 cxxbridge1$string$len + 89488\n3   chromedriver                        0x00000001006f450c cxxbridge1$string$len + 368700\n4   chromedriver                        0x000000010072e7d0 cxxbridge1$string$len + 606976\n5   chromedriver                        0x00000001006e912c cxxbridge1$string$len + 322652\n6   chromedriver                        0x00000001006e9d7c cxxbridge1$string$len + 325804\n7   chromedriver                        0x0000000100a6c490 cxxbridge1$str$ptr + 1678560\n8   chromedriver                        0x0000000100a70df8 cxxbridge1$str$ptr + 1697352\n9   chromedriver                        0x0000000100a515a4 cxxbridge1$str$ptr + 1568244\n10  chromedriver                        0x0000000100a716c8 cxxbridge1$str$ptr + 1699608\n11  chromedriver                        0x0000000100a42b48 cxxbridge1$str$ptr + 1508248\n12  chromedriver                        0x0000000100a8d7e0 cxxbridge1$str$ptr + 1814576\n13  chromedriver                        0x0000000100a8d938 cxxbridge1$str$ptr + 1814920\n14  chromedriver                        0x0000000100a9c388 cxxbridge1$str$ptr + 1874904\n15  libsystem_pthread.dylib             0x000000018afe6034 _pthread_start + 136\n16  libsystem_pthread.dylib             0x000000018afe0e3c thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m not_button \u001b[38;5;241m=\u001b[39m \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melement_to_be_clickable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m//button[contains(text(), \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNot Now\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m not_button\u001b[38;5;241m.\u001b[39mclick()\n",
      "File \u001b[0;32m~/miniconda3/envs/testing/lib/python3.12/site-packages/selenium/webdriver/support/wait.py:105\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nStacktrace:\n0   chromedriver                        0x0000000100aa4200 cxxbridge1$str$ptr + 1907280\n1   chromedriver                        0x0000000100a9c6e8 cxxbridge1$str$ptr + 1875768\n2   chromedriver                        0x00000001006b0260 cxxbridge1$string$len + 89488\n3   chromedriver                        0x00000001006f450c cxxbridge1$string$len + 368700\n4   chromedriver                        0x000000010072e7d0 cxxbridge1$string$len + 606976\n5   chromedriver                        0x00000001006e912c cxxbridge1$string$len + 322652\n6   chromedriver                        0x00000001006e9d7c cxxbridge1$string$len + 325804\n7   chromedriver                        0x0000000100a6c490 cxxbridge1$str$ptr + 1678560\n8   chromedriver                        0x0000000100a70df8 cxxbridge1$str$ptr + 1697352\n9   chromedriver                        0x0000000100a515a4 cxxbridge1$str$ptr + 1568244\n10  chromedriver                        0x0000000100a716c8 cxxbridge1$str$ptr + 1699608\n11  chromedriver                        0x0000000100a42b48 cxxbridge1$str$ptr + 1508248\n12  chromedriver                        0x0000000100a8d7e0 cxxbridge1$str$ptr + 1814576\n13  chromedriver                        0x0000000100a8d938 cxxbridge1$str$ptr + 1814920\n14  chromedriver                        0x0000000100a9c388 cxxbridge1$str$ptr + 1874904\n15  libsystem_pthread.dylib             0x000000018afe6034 _pthread_start + 136\n16  libsystem_pthread.dylib             0x000000018afe0e3c thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "not_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//button[contains(text(), \"Not Now\")]')))\n",
    "\n",
    "not_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ee85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait up to 10 seconds for the search button to be clickable on the web page\n",
    "search_button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'svg[aria-label=\"Search\"]')))\n",
    "\n",
    "# Click the search button once it becomes clickable\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed26dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target the search input field\n",
    "searchbox = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//input[@placeholder='Search']\")))\n",
    "searchbox.clear()\n",
    "\n",
    "#search for the @handle or keyword\n",
    "keyword = \"@sample-handle\"\n",
    "searchbox.send_keys(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06c2e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the keyword starts with \"@\"\n",
    "if keyword.startswith(\"@\"):\n",
    "    # Remove the \"@\" symbol\n",
    "    keyword = keyword[1:]\n",
    "    \n",
    "# Find the first element with the specified XPath that matches the keyword    \n",
    "first_result = driver.find_element(By.XPATH, f'//span[text()=\"{keyword}\"]')\n",
    "\n",
    "# Click on the found element (assuming it represents the desired search result)\n",
    "first_result.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c79c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the initial page height\n",
    "initial_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "# Create a list to store htmls\n",
    "soups = []\n",
    "\n",
    "while True:\n",
    "    # Scroll down to the bottom of the page\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Wait for a moment to allow new content to load (adjust as needed)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Parse the HTML\n",
    "    html = driver.page_source\n",
    "    \n",
    "    # Create a BeautifulSoup object from the scraped HTML\n",
    "    soups.append(BeautifulSoup(html, 'html.parser'))\n",
    "\n",
    "    # Get the current page height\n",
    "    current_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    if current_height == initial_height:\n",
    "        break  # Exit the loop when you can't scroll further\n",
    "\n",
    "    initial_height = current_height  # Update the initial height for the next iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7fa7a7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m post_urls \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m soup \u001b[38;5;129;01min\u001b[39;00m soups:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Find all anchor elements with href attributes\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     anchors \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, href\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Filter URLs that start with \"/p/\" or \"/reel/\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     post_urls\u001b[38;5;241m.\u001b[39mextend([anchor[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m anchor \u001b[38;5;129;01min\u001b[39;00m anchors \u001b[38;5;28;01mif\u001b[39;00m anchor[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstartswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/p/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/reel/\u001b[39m\u001b[38;5;124m\"\u001b[39m))])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "# List to store the post image URLs\n",
    "post_urls = []\n",
    "\n",
    "for soup in soups:\n",
    "    # Find all anchor elements with href attributes\n",
    "    anchors = soup.find_all('a', href=True)\n",
    "    \n",
    "    # Filter URLs that start with \"/p/\" or \"/reel/\"\n",
    "    post_urls.extend([anchor['href'] for anchor in anchors if anchor['href'].startswith((\"/p/\", \"/reel/\"))])\n",
    "\n",
    "# Convert the list to a set to remove duplicates\n",
    "unique_post_urls = list(set(post_urls))\n",
    "\n",
    "print(f\"before: {len(post_urls)}, after: {len(unique_post_urls)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f4c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = []\n",
    "\n",
    "# Define the query parameters to add\n",
    "query_parameters = \"__a=1&__d=dis\"\n",
    "\n",
    "# go through all urls\n",
    "for url in unique_post_urls:\n",
    "    try:\n",
    "        # Get the current URL of the page\n",
    "        current_url = driver.current_url\n",
    "\n",
    "        # Append the query parameters to the current URL\n",
    "        modified_url = \"https://www.instagram.com/\" + url + \"?\" + query_parameters\n",
    "\n",
    "        # Get URL\n",
    "        driver.get(modified_url)\n",
    "\n",
    "        # Wait for a moment to allow new content to load (adjust as needed)\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Find the <pre> tag containing the JSON data\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.XPATH, '//pre'))\n",
    "        )\n",
    "        pre_tag = driver.find_element_by_xpath('//pre')\n",
    "\n",
    "        # Extract the JSON data from the <pre> tag\n",
    "        json_script = pre_tag.text\n",
    "\n",
    "        # Parse the JSON data\n",
    "        json_parsed = json.loads(json_script)\n",
    "\n",
    "        # Add json to the list\n",
    "        json_list.append(json_parsed)\n",
    "    except (NoSuchElementException, TimeoutException, json.JSONDecodeError) as e:\n",
    "        print(f\"Error processing URL {url}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c032fe0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m all_dates \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Iterate through each JSON data in the list\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m json_data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mjson_list\u001b[49m:\n\u001b[1;32m      7\u001b[0m     \n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Extract the list from the 'items' key\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     item_list \u001b[38;5;241m=\u001b[39m json_data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Iterate through each item in the 'items' list\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json_list' is not defined"
     ]
    }
   ],
   "source": [
    "# Lists to store URLs and corresponding dates\n",
    "all_urls = []\n",
    "all_dates = []\n",
    "\n",
    "# Iterate through each JSON data in the list\n",
    "for json_data in json_list:\n",
    "    \n",
    "    # Extract the list from the 'items' key\n",
    "    item_list = json_data.get('items', [])\n",
    "    \n",
    "    # Iterate through each item in the 'items' list\n",
    "    for item in item_list:\n",
    "        \n",
    "        # Extract the date the item was taken\n",
    "        date_taken = item.get('taken_at')  # Move this line inside the loop\n",
    "\n",
    "        # Check if 'carousel_media' is present\n",
    "        carousel_media = item.get('carousel_media', [])\n",
    "        \n",
    "        # Iterate through each media in the 'carousel_media' list\n",
    "        for media in carousel_media:\n",
    "            \n",
    "            # Extract the image URL from the media\n",
    "            image_url = media.get('image_versions2', {}).get('candidates', [{}])[0].get('url')\n",
    "            \n",
    "            if image_url:\n",
    "                # Add the image URL and corresponding date to the lists\n",
    "                all_urls.append(image_url)\n",
    "                all_dates.append(date_taken)\n",
    "                print(f\"carousel image added\")\n",
    "                \n",
    "            # Extract the video URL from the media\n",
    "            video_versions = media.get('video_versions', [])\n",
    "            if video_versions:\n",
    "                video_url = video_versions[0].get('url')\n",
    "                if video_url:\n",
    "                    \n",
    "                    # Add the video URL and corresponding date to the lists\n",
    "                    all_urls.append(video_url)\n",
    "                    all_dates.append(date_taken)\n",
    "                    print(f\"carousel video added\")\n",
    "\n",
    "        # Handle cases of unique image, instead of carousel\n",
    "        image_url = item.get('image_versions2', {}).get('candidates', [{}])[0].get('url')\n",
    "        if image_url:\n",
    "            \n",
    "            # Add the image URL and corresponding date to the lists\n",
    "            all_urls.append(image_url)\n",
    "            all_dates.append(date_taken)\n",
    "            print(f\"single image added\")\n",
    "\n",
    "        # Check if 'video_versions' key exists\n",
    "        video_versions = item.get('video_versions', [])\n",
    "        if video_versions:\n",
    "            video_url = video_versions[0].get('url')\n",
    "            if video_url:\n",
    "                all_urls.append(video_url)\n",
    "                all_dates.append(date_taken)\n",
    "                print(f\"video added\")\n",
    "                \n",
    "# Print or use all collected URLs as needed\n",
    "print(len(all_urls))\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5bbfeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargé : DWN/3461162309171483022.jpg\n",
      "Téléchargé : DWN/3461162308877780454.jpg\n",
      "Téléchargé : DWN/3461162308886270524.jpg\n",
      "Téléchargé : DWN/3461162308818999739.jpg\n",
      "Téléchargé : DWN/3461162308827380080.jpg\n",
      "Téléchargé : DWN/3461162308819191953.jpg\n",
      "Téléchargé : DWN/3461162308835927784.jpg\n",
      "Téléchargé : DWN/3461162309188262056.jpg\n",
      "Téléchargé : DWN/3461162308818966621.jpg\n",
      "Téléchargé : DWN/3461162309205088591.jpg\n",
      "Téléchargé : DWN/3461162309121025004.jpg\n",
      "Téléchargé : DWN/3461162309146272216.jpg\n",
      "Téléchargé : DWN/3461162308852548405.jpg\n",
      "Téléchargé : DWN/3461162308844311879.jpg\n",
      "Téléchargé : DWN/3461162308827444316.jpg\n",
      "Téléchargé : DWN/3461162308844274717.jpg\n",
      "Téléchargé : DWN/3461162308844172455.jpg\n",
      "Téléchargé : DWN/3461162308835819392.jpg\n",
      "Téléchargé : DWN/3461162308877715738.jpg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Fonction pour télécharger un fichier\n",
    "def download_file(url, file_path):\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(file_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "    print(f\"Téléchargé : {file_path}\")\n",
    "\n",
    "# Fonction pour extraire et télécharger les médias d'un post Instagram\n",
    "def download_instagram_post(post_url):\n",
    "    # Extraire le shortcode du post à partir de l'URL\n",
    "    shortcode = post_url.split(\"/\")[-2]\n",
    "\n",
    "    # URL de l'API Instagram pour le post\n",
    "    api_url = f\"https://www.instagram.com/p/{shortcode}/?__a=1&__d=dis\"\n",
    "\n",
    "    # Ajouter l'en-tête pour éviter d'être bloqué par Instagram\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    # Récupérer les données JSON via l'API\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Impossible de récupérer les données du post.\")\n",
    "        return\n",
    "\n",
    "    media_data = response.json()['graphql']['shortcode_media']\n",
    "    \n",
    "    # Dossier de téléchargement\n",
    "    download_dir = \"DWN\"\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "    # Télécharger les vidéos ou les images\n",
    "    if media_data['is_video']:\n",
    "        # Télécharger la vidéo\n",
    "        video_url = media_data['video_url']\n",
    "        file_path = os.path.join(download_dir, f\"{shortcode}.mp4\")\n",
    "        download_file(video_url, file_path)\n",
    "    else:\n",
    "        # Vérifier s'il s'agit d'un carrousel de plusieurs images/vidéos\n",
    "        if 'edge_sidecar_to_children' in media_data:\n",
    "            for edge in media_data['edge_sidecar_to_children']['edges']:\n",
    "                node = edge['node']\n",
    "                if node['is_video']:\n",
    "                    # Télécharger la vidéo du carrousel\n",
    "                    video_url = node['video_url']\n",
    "                    file_path = os.path.join(download_dir, f\"{node['id']}.mp4\")\n",
    "                    download_file(video_url, file_path)\n",
    "                else:\n",
    "                    # Télécharger l'image du carrousel\n",
    "                    image_url = node['display_url']\n",
    "                    file_path = os.path.join(download_dir, f\"{node['id']}.jpg\")\n",
    "                    download_file(image_url, file_path)\n",
    "        else:\n",
    "            # Cas d'une image unique\n",
    "            image_url = media_data['display_url']\n",
    "            file_path = os.path.join(download_dir, f\"{shortcode}.jpg\")\n",
    "            download_file(image_url, file_path)\n",
    "\n",
    "# Lien Instagram à télécharger (remplace par ton lien)\n",
    "post_url = \"https://www.instagram.com/p/DAIhMxsIDwn/?img_index=1\"\n",
    "download_instagram_post(post_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df201782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: DWN/woooow\n",
      "Downloaded: DWN/woooow\n",
      "Downloaded 2 files to DWN\n"
     ]
    }
   ],
   "source": [
    "download_dir = \"DWN\"\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# Create subfolders for images and videos\n",
    "image_dir = os.path.join(download_dir, \"images\")\n",
    "video_dir = os.path.join(download_dir, \"videos\")\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "os.makedirs(video_dir, exist_ok=True)\n",
    "\n",
    "# Initialize counters for images and videos\n",
    "image_counter = 1\n",
    "video_counter = 1\n",
    "\n",
    "# Iterate through URLs in the all_urls list and download media\n",
    "for index, url in enumerate(all_urls, 0):\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Extract file extension from the URL\n",
    "    url_path = urlparse(url).path\n",
    "    file_extension = os.path.splitext(url_path)[1]\n",
    "\n",
    "    # Determine the file name based on the URL\n",
    "    if file_extension.lower() in {'.jpg', '.jpeg', '.png', '.gif'}:\n",
    "        file_name = f\"down.png\"\n",
    "        destination_folder = image_dir\n",
    "        image_counter += 1\n",
    "    elif file_extension.lower() in {'.mp4', '.avi', '.mkv', '.mov'}:\n",
    "        file_name = f\"-vid-.mp4\"\n",
    "        destination_folder = video_dir\n",
    "        video_counter += 1\n",
    "    else:\n",
    "        # Default to the main download directory for other file types\n",
    "        file_name = f\"woooow\"\n",
    "        destination_folder = download_dir\n",
    "\n",
    "    # Save the file to the appropriate folder\n",
    "    file_path = os.path.join(destination_folder, file_name)\n",
    "    \n",
    "    # Write the content of the response to the file\n",
    "    with open(file_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "\n",
    "    print(f\"Downloaded: {file_path}\")\n",
    "\n",
    "# Print a message indicating the number of downloaded files and the download directory\n",
    "print(f\"Downloaded {len(all_urls)} files to {download_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
