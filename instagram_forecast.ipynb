{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import os\n",
    "import requests\n",
    "import base64\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "import base64\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from moviepy.editor import *\n",
    "import pandas as pd\n",
    "import whisper\n",
    "import os\n",
    "import requests\n",
    "import base64\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import ffmpeg\n",
    "import easyocr\n",
    "import re\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_FOLDER = \"FRAMES\"\n",
    "RAW_DATA_FOLDER = \"DATA\"\n",
    "\n",
    "os.mkdir(FRAME_FOLDER)\n",
    "os.mkdir(RAW_DATA_FOLDER)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = f\"{RAW_DATA_FOLDER}/audio\"\n",
    "audio_filename = f\"{RAW_DATA_FOLDER}/audio.mp3\"\n",
    "output_metadata_filename=f\"{RAW_DATA_FOLDER}/video_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"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\"\n",
    "gpt_client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_file(url, file_path):\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(file_path, 'wb') as file:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "    print(f\"Download : {file_path}\")\n",
    "\n",
    "def get_post_description(post_url):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(post_url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    description = soup.find('meta', {'property': 'og:description'})['content']\n",
    "    driver.quit()\n",
    "    print(f\"Post description : {description}\")\n",
    "    return description\n",
    "\n",
    "def convert_video_to_audio(filepath):\n",
    "    video = VideoFileClip(filepath)\n",
    "    video.audio.write_audiofile(f\"{RAW_DATA_FOLDER}/audio.mp3\")\n",
    "    video_time = video.duration\n",
    "    return video_time\n",
    "\n",
    "def download_instagram_post(post_url):\n",
    "    shortcode = post_url.split(\"/\")[-2]\n",
    "    description = get_post_description(post_url)\n",
    "    api_url = f\"https://www.instagram.com/p/{shortcode}/?__a=1&__d=dis\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "    }\n",
    "    response = requests.get(api_url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(\"Impossible to fetch post data.\")\n",
    "        return\n",
    "\n",
    "    media_data = response.json()['graphql']['shortcode_media']\n",
    "    if media_data['is_video']:\n",
    "        video_url = media_data['video_url']\n",
    "        video_title = os.path.join(RAW_DATA_FOLDER, f\"{shortcode}.mp4\")\n",
    "        download_file(video_url, video_title)\n",
    "        video_time = convert_video_to_audio(video_title)\n",
    "    else:\n",
    "        if 'edge_sidecar_to_children' in media_data:\n",
    "            for edge in media_data['edge_sidecar_to_children']['edges']:\n",
    "                node = edge['node']\n",
    "                if node['is_video']:\n",
    "                    video_url = node['video_url']\n",
    "                    video_title = os.path.join(RAW_DATA_FOLDER, f\"{node['id']}.mp4\")\n",
    "                    download_file(video_url, video_title)\n",
    "                    video_time = convert_video_to_audio(video_title)\n",
    "                else:\n",
    "                    image_url = node['display_url']\n",
    "                    video_title = os.path.join(RAW_DATA_FOLDER, f\"{node['id']}.jpg\")\n",
    "                    download_file(image_url, video_title)\n",
    "        else:\n",
    "            image_url = media_data['display_url']\n",
    "            video_title = os.path.join(RAW_DATA_FOLDER, f\"{shortcode}.jpg\")\n",
    "            download_file(image_url, video_title)\n",
    "    return description, video_time, video_title\n",
    "\n",
    "def transcript_audio_to_text(audio_filename, is_music):\n",
    "    if is_music is False : \n",
    "        model = whisper.load_model(\"base\")\n",
    "        result = model.transcribe(audio_filename)\n",
    "        text = result[\"text\"]\n",
    "        print(f\"text : {result[\"text\"]}\")\n",
    "        return text\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "def extract_video_frames(video_title , video_time, fps = 1):\n",
    "    if video_time > 150:\n",
    "        print(\"Video too long, no video extraction\")\n",
    "        return \n",
    "    else:\n",
    "        output_frames = f'{FRAME_FOLDER}/frame_%04d.png'\n",
    "        (\n",
    "            ffmpeg\n",
    "            .input(video_title)\n",
    "            .output(output_frames, vf=f'fps={fps}')\n",
    "            .run()\n",
    "        )\n",
    "\n",
    "        print(\"Frames extraction done.\")\n",
    "\n",
    "def create_reader():\n",
    "    reader = easyocr.Reader(['en','fr','es','it','de'])\n",
    "    return reader\n",
    "\n",
    "\n",
    "def extract_text_from_frames(reader, frame_folder, video_time):\n",
    "    if video_time > 150 : \n",
    "        print(\"no frame extraction\")\n",
    "        return \" \"\n",
    "    else:\n",
    "        video_frame_text = []\n",
    "        for frame in os.listdir(frame_folder):\n",
    "            result = reader.readtext(f\"{frame_folder}/{frame}\")\n",
    "            for detection in result:\n",
    "                video_frame_text.append(detection[1])\n",
    "        print( video_frame_text)\n",
    "        return video_frame_text\n",
    "\n",
    "\n",
    "def generate_input_text(video_description, video_audio, video_frame_text):\n",
    "    generated_texts = video_description , video_audio ,  \" \".join(video_frame_text)\n",
    "    print(generated_texts)\n",
    "    return generated_texts\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    text = re.sub(r'[@#]\\w+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s,.\\'â€™-]', '', text) \n",
    "    return text\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    words = text.split()\n",
    "    seen = set()\n",
    "    unique_words = []\n",
    "    for word in words:\n",
    "        if word not in seen:\n",
    "            unique_words.append(word)\n",
    "            seen.add(word)\n",
    "    \n",
    "    return ' '.join(unique_words)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = re.sub(r\"[^\\w\\s,]\", \"\", text)\n",
    "    cleaned_text = re.sub(r\",+\", \",\", cleaned_text)\n",
    "    cleaned_text = cleaned_text.replace(\",,\", \",\")  \n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def nlp_forecast(client, text): \n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": \"You are usefull to seek places in a text with their city and country\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": (\n",
    "            \"\"\"\n",
    "            Instructions:\n",
    "                - Given the text at the end, find all the places to visit quote in this text. \n",
    "                - Take also care to the Name of the places who can be brand\n",
    "                - Return the number of places you find\n",
    "                - Return the city of these places in English\n",
    "                - Return the country of these places in English\n",
    "                - Do not return the same place multiple time\n",
    "                - Return only in the python dictionary format like below\n",
    "                - Do not include any additional formatting, such as markdown code blocks\n",
    "\n",
    "\n",
    "            {\n",
    "            \"place_number\" : \"<number of places>\",\n",
    "            \"place_1\" : \"<first place you find in the text>\",\n",
    "            \"place_2\" : \"<second place you find in the text>\", \n",
    "            ...,\n",
    "            \"place_n\" : \"<the nth place you find in the text>\n",
    "            \"city\" :\" <the city of these places>\", \n",
    "            \"country\" : \"<the country of these places>\"\n",
    "             },\n",
    "\n",
    "             \n",
    "            The text could be bad formated but just focus to find similitude with the places you know \n",
    "            There is the text to analyse :\n",
    "            \"\"\" + text\n",
    "            )\n",
    "        }\n",
    "    ]\n",
    "    )\n",
    "    output = completion.choices[0].message.content\n",
    "    print(output)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m post_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menter the tiktok or instagram url : \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m video_description, video_time, video_title \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_instagram_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpost_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(video_title)\n\u001b[1;32m      4\u001b[0m video_audio \u001b[38;5;241m=\u001b[39m transcript_audio_to_text(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mRAW_DATA_FOLDER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/audio.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[45], line 29\u001b[0m, in \u001b[0;36mdownload_instagram_post\u001b[0;34m(post_url)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_instagram_post\u001b[39m(post_url):\n\u001b[0;32m---> 29\u001b[0m     shortcode \u001b[38;5;241m=\u001b[39m \u001b[43mpost_url\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     30\u001b[0m     description \u001b[38;5;241m=\u001b[39m get_post_description(post_url)\n\u001b[1;32m     31\u001b[0m     api_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.instagram.com/p/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshortcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/?__a=1&__d=dis\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def forecast_instagram_places(post_url):\n",
    "    video_description, video_time, video_title = download_instagram_post(post_url)\n",
    "    print(video_title)\n",
    "    video_audio = transcript_audio_to_text(f\"{RAW_DATA_FOLDER}/audio.mp3\", False)\n",
    "    print(f\"video time : {video_time} seconds\")\n",
    "    extract_video_frames(video_title, video_time)\n",
    "    reader = create_reader()\n",
    "    video_frame_text = extract_text_from_frames(reader, frame_folder=FRAME_FOLDER, video_time=video_time)\n",
    "    input_text = generate_input_text(video_description, video_audio, video_frame_text)\n",
    "    cleaned_text = clean_text(str(input_text))\n",
    "    new = remove_duplicates(cleaned_text)\n",
    "    new = preprocess_text(new)\n",
    "    print(\"preprocessed text : \" + new)\n",
    "    output = nlp_forecast(gpt_client, str(input_text))\n",
    "    dico = eval(output)\n",
    "    data = pd.DataFrame(dico, index=[0])\n",
    "    print(data.head())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
